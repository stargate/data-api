# Data API Error Objects V2
#
# This file contain the error messages that are returned by the Data API
#
# The error descriptions in this file are ready by the APIException classes to create the content for the errors.
# That is, only errors defined in the code are read from this file, see the APIException class in the code
# for a description of how the errors are defined and manged.
#
# Errors have the following hierarchy:
# Family -> (optional) Scope -> Code
#
# Where
# * Family: Identifies if the error relates to the client request or the server processing, analogous
#           to the 4XX and 5XX HTTP status codes. Supported values are REQUEST or SERVER. In this file they are
#           represented by the request-errors and server-errors keys.
# * Scope: Optionally identifies the part of the request or server processing that caused the fault, for example "FILTER"
#          when there is a problem in the filter clause. Scope generally map to a concrete APIException class such as
#          FilterException.
# * Code: A unique string identifying the error.
#
# All values are strings and must be UPPER_SNAKE_CASE_1 supporting upper case alpha and digits.
#
# FILE LAYOUT
# ===========
#
# "snippets" is a list of text snippets than can be included in any error body, the snippets are included in the
# variables when running the tempalte for the body of the error. Snippets are referenced using `${SNIPET.<NAME>}`
# where <NAME> is the name of the snippet key.
# Each snippet has:
# - name: UPPER_SNAKE_CASE_1
# - body: A string with the text of the snippet, recommend using the `|-` to trim trailing newlines.
#
# "request-errors" and "server-errors" are lists of error objects, for the REQUEST and SERVER family respectively.
# Each error object has:
# - scope: UPPER_SNAKE_CASE_1
# - code: UPPER_SNAKE_CASE_1
# - http-status-override: (optional) The HTTP status code to return when this error is thrown. If not present, the
#                           default status code is 200 for most things. This is not returned in the error object JSON
#                           It is used to override the HTTP status code in the response.
#                           NOTE: NO checking is done to confirm this is a valid HTTP status code.
# - title: A short title for the error, that must not change between instances of the error.
# - body: A longer body that may contain ${vars} to be passed by the code when created, and references to snippets.
#         This can be a multi line string, recommend using the `|-` to trim trailing newlines.
#
# NOTE: Please keep the entries sorted on their name for snippets, or scope and code for errors. Please add a
#       new line after each entry, using the `|-` to trim trailing newlines.

# ================================================================================================================
# ================================================================================================================
#                                           SNIPPETS
# ================================================================================================================
# ================================================================================================================

snippets:
  - name: RETRY
    body: |-
      It is safe to retry this request.

  - name: RETRY_UNKNOWN
    body: |-
      Review the Error Message before retrying this request.

  - name: INEFFICIENT_FILTER
    body: |-
      The query was executed without taking advantage of the primary key or indexes on the table, this can have performance implications on large tables.
      
      See documentation for best practices for filtering.

  - name: INEFFICIENT_SORT
    body: |-
      The command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.
      
      See documentation for best practices for sorting.

  - name: RESEND_USING_ONLY_DEFINED_COLUMNS
    body: |-
      Resend the command using only defined columns.

  - name: VECTOR_SORT_EXPLANATION
    body: |-
      A vector sort in the sort clause identifies the vector column by name and then provides either:  
      - The vector as an array of decimal numbers.
      - The vector as a base64 encoded `{"$binary": "base64-encoded-vector"}` object.
      - A string to be vectorized if enabled for the column.

  - name: CURRENTLY_UNSUPPORTED
    body: |-
      Currently API Tables has limited support for: 
      
      - Cassandra `timeuuid`, `counter` types.
      - Cassandra User Defined Types (UDT) and Tuple types.
      - Filtering and indexing on Cassandra collection types `list`, `map`, `set`.
      - Defining `maps`, `list`, or `set` columns using any key type other than `text` or `ascii`.
      
      Support for these features will be expanded in future releases.

  - name: ADD_VECTORIZE_CONFIG
    body: |-
      Vectorize configuration can be added when the table is created or later using the `alterTable` command.

  - name: EXPLAIN_PARTITIONING
    body: |-
      Rows in API Tables are partitioned by the partition key, which can be one or more columns. All rows in the same partition share the same partition key values and can be very quickly read in the order of the partition sorting.




# ================================================================================================================
# ================================================================================================================
#                                           REQUEST Errors
# ================================================================================================================
# ================================================================================================================

# ================================================================================================================
# Family: REQUEST         Scope: NONE
# ================================================================================================================

request-errors:
  # UNSCOPED request errors

  - scope:
    code: UNSUPPORTED_TABLE_COMMAND
    title: Command is not supported by Tables
    body: |-
      The command is not supported by Tables in the API.  
      
      While many commands operate on both Tables and Collections, some commands can only be run against Tables or Collections. 
      
      The commands supported by tables are: ${tableCommands}.
      The commands supported by collections are: ${collectionCommands}.
      
      The unsupported command ran against the table: ${keyspace}.${table}
      The unsupported command was: ${unsupportedCommand}.
      
      Resend using one of the supported commands.

  - scope:
    code: UNSUPPORTED_COLLECTION_COMMAND
    title: Command is not supported by Collections
    body: |-
      The command is not supported by Collections in the API.  
      
      While many commands operate on both Tables and Collections, some commands can only be run against Tables or Collections. 
      
      The commands supported by collections are: ${collectionCommands}.
      The commands supported by tables are: ${tableCommands}.
      
      The unsupported command ran against the collection: ${keyspace}.${table}
      The unsupported command was: ${unsupportedCommand}.
      
      Resend using one of the supported commands. 

  - scope:
    code: UNSUPPORTED_RERANKING_COMMAND
    title: Reranking not enabled for Collection
    body: |-
      The `findAndRerank` is not enabled for the Collection.
      
      The Command is only supported for Collections that are configured with `vector`, `lexical`, and `rerank` configurations. They additionally require a vectorize configuration if `$vectorize` is used.
      
      Resend using a supported Collection. 

  # unscoped because this touches both the sort and the options
  - scope:
    code: MISSING_RERANK_QUERY_TEXT
    title: Rerank query text is missing
    body: |-
      The findAndRerank command is missing the text to use as the query with the reranking model.

      Reranking involves using a model to compare passages of text to a user query. 
      
      The query can be specified using either: 
      * `$hybrid` field in the sort clause, e.g. `{"$hybrid": "query text"}`.
      * `$vectorize` field in the sort clause, when using different sorting for vectorize and lexical, e.g. `{"$hybrid":  {"$vectorize": "query text"}}`.
      * `rerankQuery` field in the options clause, e.g. `{"rerankQuery": "query text"}`.
      
      When specified the `rerankQuery` option takes priority. In all cases the query text must be a non blank text value. 
      
      Resend the command including the query text for reranking.
# ================================================================================================================
# Family: REQUEST         Scope: DOCUMENT
# ================================================================================================================

 # DOCUMENT request errors
  - scope: DOCUMENT
    code: MISSING_PRIMARY_KEY_COLUMNS
    title: Primary key columns missing
    body: |-
      All primary key columns must be provided when inserting a document into a table. 
      
      The table ${keyspace}.${table} defines the primary key columns: ${primaryKeys}.
      
      The command included values for primary key columns: ${providedKeys}.
      The command did not include values for primary key columns: ${missingKeys}.
      
      Resend the command including the missing primary key columns.

  # NOTE: UNKNOWN_TABLE_COLUMNS is also in the FILTER scope
  - scope: DOCUMENT
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in documents are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be included when inserted a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: DOCUMENT
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in documents are not supported
    body: |-
      Only supported column types can be included when inserting a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.

  - scope: DOCUMENT
    code: INVALID_COLUMN_VALUES
    title: Column values in documents are not valid
    body: |-
      Only values that are supported by the column data type can be included when inserting a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that had invalid values: ${invalidColumns}.
      
      Resend the command using only supported column values.

  - scope: DOCUMENT
    code: UNSUPPORTED_VECTORIZE_CONFIGURATIONS
    title: Unsupported combination of vectorize configurations
    body: |-
      A request can include only one unique combination of provider, model, and dimension for vectorization.
      
      The following combinations were included in your request: ${vectorizeIdentities}.
      
      Resend the command using only one unique combination of provider, model, and dimension for vectorization.
      
      Support for these features will be expanded in future releases.

  - scope: DOCUMENT
    code: UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize not supported on column with missing vectorize configuration
    body: |-
      Vectorize can only be used with columns that have a vectorize configuration. 
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize definition: ${validVectorizeColumns}.
      The command included the following vector columns without vectorize definition: ${invalidVectorizeColumns}.
      
      Resend the command using only vector columns with a vectorize definition.

# ================================================================================================================
# Family: REQUEST         Scope: FILTER
# ================================================================================================================

  # NOTE: UNKNOWN_TABLE_COLUMNS is also in the DOCUMENT scope
  - scope: FILTER
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the filter are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be filtered on.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The filter included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: FILTER
    code: INVALID_FILTER_COLUMN_VALUES
    title: Column value in filter is not valid
    body: |-
      Only values that are supported by the column data type can be included when filtering.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the column ${invalidColumn} that has ${columnType} type defined.
      
      Resend the command using only supported column values.

  - scope: FILTER
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in the filter are not supported
    body: |-
      Only column types supported by the API can be filtered on.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.  

  - scope: FILTER
    code: UNSUPPORTED_FILTERING_FOR_COLUMN_TYPES
    title: Column types in the filter do not support the filter operations
    body: |-
      Filtering is only supported on primitive data types such as `text` not on container types such as `list`, `set`, `map`, or `vector`.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included unsupported filters on the columns: ${complexColumns}.
      
      Resend the command using only supported column types.  

  - scope: FILTER
    code: UNSUPPORTED_COMPARISON_FILTER_AGAINST_DURATION
    title: Duration data type does not support comparison filters
    body: |-
      Filtering using the comparison operations ($lt, $gt, $lte, $gte) is not supported against `duration` column types.
    
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request used a comparison operation on duration columns: ${durationFilters}.
      
      Resend the command using only supported operations on `duration` columns. 

  - scope: FILTER
    code: MISSING_FILTER_FOR_UPDATE_DELETE
    title: Update and delete commands require a filter
    body: |-
      Update and delete commands for Tables require a filter.
      
      These commands require a filter that identifies a either a single row (for `updateOne` and `deleteOne`) or a partition and a sequence of rows (for `deleteMany`). 
      
      Note: using the `deleteMany` command without a filter truncates all rows from the table.
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeyColumns}.
      
      Resend the command using a filter.

  - scope: FILTER
    code: UNSUPPORTED_FILTER_FOR_UPDATE_ONE_DELETE_ONE
    title: updateOne and deleteOne commands only support filtering using $eq
    body: |-
      The Filtering using the non `$eq` filter operations can select more than one row, and so cannot be used with the `updateOne` and `deleteOne` commands as they can only modify one row.
      
      The command used an invalid filter on the columns: ${unsupportedFilterColumns}.
      
      Resend the command only using `$eq` filters.

  - scope: FILTER
    code: UNSUPPORTED_NON_PRIMARY_KEY_FILTER_FOR_UPDATE_DELETE
    title: Update and delete commands only support filtering on the primary key
    body: |-
      The Update or delete commands can only filter using columns that are part of the primary key.
      
      The table ${keyspace}.${table} defines the primaryKeys: ${primaryKeyColumns}.
      The filter used the non primary key columns: ${nonPrimaryKeyFilters}
      
      Resend the command using with a filter that only uses the primary key columns.

  - scope: FILTER
    code: MISSING_FULL_PRIMARY_KEY_FOR_UPDATE_DELETE
    title: updateOne and deleteOne commands require filtering on the full primary key
    body: |-
      The `updateOne` and `deleteOne`commands can only filter using the fully specify the primary key for the table.

      The table ${keyspace}.${table} defines the primaryKeys: ${primaryKeyColumns}.
      The filter was missing the primary key columns: ${missingPrimaryKeyFilters}.
      
      Resend the command using a filter that fully specifies the primary key to identify a single row.

  - scope: FILTER
    code: INVALID_PRIMARY_KEY_FILTER
    title: Primary key filtering must specify columns in schema order
    body: |-
      The command requires a filter on the primary key that specifies all of the partitioning keys, and the partition sort keys in order.
      
      If a partition sort key is excluded, then all following partition sort keys must be excluded. 
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      
      The filter has the following issues: 
        - Missing Partition Keys: ${missingPartitionKeys}.
        - Out of order Partition Sort Keys: ${outOfOrderClusteringKeys}.
      
      Resend the command using a filter that includes all partitioning keys and optionally the partitioning sort keys in order. 

# ================================================================================================================
# Family: REQUEST         Scope: UPDATE
# ================================================================================================================

  - scope: UPDATE
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the update are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be updated.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The update included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: UPDATE
    code: INVALID_UPDATE_COLUMN_VALUES
    title: Column value in update clause is not valid
    body: |-
      Only values that are supported by the column data type can be included when updating.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The update included invalid values for the columns: ${invalidColumns}.
      
      Resend the command using only supported column values.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR
    title: Update operator is not supported by target columns
    body: |-
      Only update operators that are supported by the column type can be used in the update clause.
      
      Note, $push and $pullAll are only supported against map, set, list columns.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command used the update operator: ${operator}.
      The operation was not supported by the columns: ${unsupportedColumns}.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_DOC_ID
    title: Update operators cannot be used on _id field
    body: |-
      The command used the update operator: ${operator}.
      _id field cannot be updated using update operators.
      
      Resend the command without trying to update _id field.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_LEXICAL
    title: Update operator cannot be used on $lexical field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $lexical field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_VECTOR
    title: Update operator cannot be used on $vector field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $vector field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_VECTORIZE
    title: Update operator cannot be used on $vectorize field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $vectorize field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: INVALID_PUSH_OPERATOR_USAGE
    title: The command has invalid usage of $push operator
    body: |-
      The command has invalid usage of $push operator, ${reason}.
      
      Update operator $push works for adding single element, combine $push with $each for adding multiple elements.
      
      E.G.
      Push single element to set/list. 
      {"$push": {"listColumn": "value"}}
      Push multiple elements to set/list. 
      {"$push": {"listColumn": {"$each": ["value1","value2"]}}}
      Push single entry to map.
      {"$push": {"mapColumn": ["key1", "value1"]}} or {"$push": {"mapColumn": {"key1":"value1"}}}
      Push multiple entries to map.
      {"$push": {"mapColumn": {"$each": [["key1","value1"],["key2", "value2"]]}}} or {"$push": {"mapColumn": {"$each": [{"key1":"value1"},{"key2":"value2"}]}}}

      Resend the command with valid usage of $push operator.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_FOR_PRIMARY_KEY_COLUMNS
    title: Primary key columns cannot be updated
    body: |-
      Columns in the primary key for the table cannot be updated. 
      
      This includes both the partitioning keys and the partitioning sort keys. 
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      The update included the following primary keys: ${updateOnPrimaryKeyColumns}.
      
      Resend the command without updating primary key columns.

  - scope: UPDATE
    code: MISSING_UPDATE_OPERATIONS
    title: Update operation requires at least one operation
    body: |-
      The command did not include any non empty update operations to change the columns in the table.
      
      Supported update operations are ${supportedUpdateOperations}.
      
      Resend the command using at least one update operation.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATIONS_FOR_TABLE
    title: Update operation not supported by Tables
    body: |-
      The command included update operations that are not supported by Tables.
      
      API Tables supports the update operations: ${supportedUpdateOperations}.
      The update included the unsupported operations: ${usedUnsupportedUpdateOperations}.
      
      Resend the command using only supported update operations.

  - scope: UPDATE
    code: UNSUPPORTED_OVERLAPPING_UPDATE_OPERATIONS
    title: Columns cannot be changed by multiple update operations
    body: |-
      The command included multiple update operations that attempted to change the same column. For example, attempting to both $set and $unset a column.
    
      Multiple assignments attempted to change the columns: ${duplicateAssignmentColumns}.
      
      Resend the command using a single update operation for each column.

# Note UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION is a duplicate for Document scope, this one is used for Update scope.
  - scope: UPDATE
    code: UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize requires a column with vectorize definition
    body: |-
      Vectorize can onl be performed on columns that have a vectorize configuration.
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize configuration: ${validVectorizeColumns}.
      The update included the following vector columns without vectorize configuration: ${invalidVectorizeColumns}.
      
      Resend the command vector columns with vectorize enabled.

  - scope: UPDATE
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in update clause are not supported
    body: |-
      Only supported column types can be included when updating columns in a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.


  # ================================================================================================================
  # Family: REQUEST         Scope: WARNING
  # ================================================================================================================

  - scope: WARNING
    code: MISSING_INDEX
    title: Filter includes columns that are not indexed
    body: |-
      The filter includes columns that are not indexed. 
      
      The table ${keyspace}.${table} has the primary key: ${primaryKey}.
      And has indexes on the columns: ${indexedColumns}.
      The request filtered on the un-indexed columns: ${unindexedFilters}.
      
      Note: There may be a small delay in newly created indexes propagating through the system, this warning may be ignored if the column(s) were recently indexed.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: NOT_EQUALS_UNSUPPORTED_BY_INDEXING
    title: Use of $ne (not equals) on indexed columns
    body: |-
      The filter uses $ne (not equals) on columns that, while indexed, are still inefficient to filter on using not equals.  
      
      Filtering using $ne on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $ne to the columns: ${inefficientFilters}.
      
      ${SNIPPET.INEFFICIENT_FILTER}


  - scope: WARNING
    code: COMPARISON_FILTER_UNSUPPORTED_BY_INDEXING
    title: Use of $lt, $gt, $lte, $gte (comparison filter) on indexed columns
    body: |-
      The filter uses $lt, $gt, $lte, $gte (comparison filters) on columns that, while indexed, are still inefficient to filter on.  
      
      Filtering using $lt, $gt, $lte, $gte on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $lt, $gt, $lte, $gte to the indexed columns: ${inefficientFilterColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: NOT_IN_FILTER_UNSUPPORTED_BY_INDEXING
    title: Use of $nin on indexed columns
    body: |-
      The filter uses $nin on columns that, while indexed, are still inefficient to filter on.  
      
      Filtering using $nin on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $nin to the indexed columns: ${inefficientFilterColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: ZERO_FILTER_OPERATIONS
    title: Zero operations provided in query filter
    body: |-
      Zero filters were provided in the filter for this query. 
      
      Providing zero filters will return all rows in the table, which may have poor performance when the table is large. For the best performance, include one or more filters using the primary key or indexes.
      
      The table ${keyspace}.${table} has the primary key: ${primaryKey}.
      And has indexes on the columns: ${indexedColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: INCOMPLETE_PRIMARY_KEY_FILTER
    title: Incomplete filter on table primary key
    body: |-
      The filter only specified columns from the primary key, but did not specify the full primary key for the table.  
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      The filter has the following issues: 
        - Missing Partition Keys: ${missingPartitionKeys}.
        - Out of order Partition Sort Keys: ${outOfOrderClusteringKeys}.
      
      For the best performance, filter on all partition columns and optionally on clustering columns in the order they are specified. 
      
      ${SNIPPET.INEFFICIENT_FILTER}      

  - scope: WARNING
    code: DEPRECATED_COMMAND
    title: Deprecated command
    body: |-
      A deprecated command was used, it may still be used but will be removed in future releases.
      
      The deprecated command is: ${deprecatedCommand}.
      The new command to use is: ${replacementCommand}.
      
      Please check the documentation for the new command and update your code.

  - scope: WARNING
    code: QUERY_RETRIED_DUE_TO_INDEXING
    title: Query was retried due lack of primary or index usage
    body: |-
      The Data API failed to detect that the query generated by the command was inefficient due to a lack of primary key or index usage, and so it was retried after failing.
      
      To avoid needing to retry queries the Data API attempts to identify inefficient queries to the database before executing them, when doing this it can also provide detailed guidance on how to improve the command filter. If the analysis fails the query may need to be retried. 
      
      The original query used the CQL: ${originalCql}.
      The original query used the parameters: ${originalParameters}.
      
      The API appended the CQL optional `ALLOW FILTERING` to the query and retried.
      
      ${SNIPPET.INEFFICIENT_FILTER}


  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING
    title: Sorting by non partition sorting columns
    body: |-
      The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.
            
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The command sorted on the columns: ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_SKIP_OPTIONS
    title: Sorting uses skip option, performing as in memory sort
    body: |-
      Sorting uses skip option, performing as in memory sort

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_PARTITION_KEY_NOT_RESTRICTED
    title: Sorting with partition key not restricted correctly in filter clause
    body: |-
      The command wants to perform sort, however the filter clause does not have partition keys correctly restricted.
      
      When sorting by the partition sorting columns, partition keys needs to restricted by $eq in filter clause.
      
      The table ${keyspace}.${table} has the partition keys: ${partitionKeys}.
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause used the columns (in order) : ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_MISSING_PARTITION_SORTING
    title: Sorting with missing partition sorting columns
    body: |-
      The command used columns in the sort clause that are all part of the partition sorting, however the sort clause was missing some of the partition sorting columns.
      
      When sorting by the partition sorting columns, if a column is skipped then all following columns must also be skipped.
      
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause skipped a column and then included the columns : ${outOfOrderClusteringKeys}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_OUT_OF_ORDER_PARTITION_SORTING
    title: Sorting on out of order partition sorting columns
    body: |-
      The command used columns in the sort clause that are all part of the partition sorting, however the sort clause used a different column order to the partition sorting.

      When sorting by the partition sorting columns, the columns must be in the same order as the partition sorting.

      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause used the columns (in order) : ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  # ================================================================================================================
  # Family: REQUEST         Scope: PROJECTION
  # ================================================================================================================

  - scope: PROJECTION
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in projection are not supported
    body: |-
      Only supported column types can be included when reading from a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns cannot be read: ${unsupportedColumns}.
      
      Resend the command using only supported column types.

  - scope: PROJECTION
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the projection are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be included in the projection.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The projection included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  # ================================================================================================================
  # Family: REQUEST         Scope: SCHEMA
  # ================================================================================================================

  # aaron errors
  - scope: SCHEMA
    code: UNKNOWN_PARTITION_SORT_COLUMNS
    title: Partition sort columns are not defined in the table schema
    body: |-
      The columns used for partition sorting are not present in the table schema.
            
      The table definition includes the columns: ${tableColumns}.
      The partition sort includes the unknown columns: ${unknownColumns}.
      
      Resend the command using only columns included in the table definition.

  - scope: SCHEMA
    code: UNKNOWN_PARTITION_COLUMNS
    title: Partition columns are not defined in the table schema
    body: |-
      The column used to partition by are not present in the table schema.
      
      The table definition includes the columns: ${tableColumns}.
      The partition includes the unknown columns: ${unknownColumns}.
      
      Resend the command using only columns included in the table definition.

  - scope: SCHEMA
    code: MISSING_PARTITION_COLUMNS
    title: Partitioning keys are required for Tables
    body: |-
        The table definition must have at least one partition key.
      
        ${SNIPPET.EXPLAIN_PARTITIONING}
      
        The table definition includes the columns: ${tableColumns}.
      
        Resend the command using at least one partition key. 

  - scope: SCHEMA
    code: MISSING_ALTER_TABLE_OPERATIONS
    title: Alter table command must include operations
    body: |-
      The `alterTable` command must contain at least one operation to alter the table schema, such as adding or dropping columns.
      
      The command included the empty operation: ${missingTableOperation}
      
      Resend the command including changes to the table.

  - scope: SCHEMA
    code: MISSING_DIMENSION_IN_VECTOR_COLUMN
    title: Dimension is required for vector column if embedding service is not specified
    body: |-
        The dimension is required for vector columns if the embedding service is not specified.
        
        The command attempted to create the vector column without a dimension.
        
        Resend the command using a dimension for the vector columns.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_COLUMNS
    title: Columns with the same name are defined in the table schema
    body: |-
      Column names must be unique in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included the following duplicate columns: ${duplicateColumns}.
      
      Resend the command using only new columns.

  - scope: SCHEMA
    code: CANNOT_ANALYZE_ENTRIES_ON_MAP_COLUMNS
    title: Can not create index on map column with index function entries and specify analyze options
    body: |-
      Index function `entries` can not apply to map column when analyze options are specified.
      
      The command contains analyze options: ${analyzedOptions}.
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      
      Resend the command without options.

  - scope: SCHEMA
    code: CANNOT_DROP_PRIMARY_KEY_COLUMNS
    title: Primary key columns cannot be dropped from the table schema
    body: |-
      Primary key columns cannot be dropped from the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The table has the primary keys: ${primaryKeys}.
      The command attempted to drop the primary key columns: ${droppedColumns}. 
      
      Resend the command without dropping the primary key columns.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_COLUMNS
    title: Columns cannot be dropped if they are not defined in the table schema
    body: |-
      The command attempted to drop columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to drop the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_DROP_INDEXED_COLUMNS
    title: Columns used in the indexes cannot be dropped
    body: |-
      Columns that are indexed cannot be dropped from the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has indexes on the columns: ${indexedColumns}.
      The command attempted to drop the indexed columns: ${droppedIndexedColumns}.
      
      Resend the command without dropping the indexed columns.

  - scope: SCHEMA
    code: DEPRECATED_AI_MODEL
    title: Cannot use deprecated model.
    body: |-
      The command attempted to create or alter a Collection or Table to use a AI Model that has been marked as deprecated. Deprecated models are only supported by the API for existing use and will later be removed.

      The model is: ${model}. It is at ${modelStatus} status.
      ${message}
      
      Resend the command using supported model.

  - scope: SCHEMA
    code: END_OF_LIFE_AI_MODEL
    title: Cannot use end of life model.
    body: |-
      The command attempted to use an AI Model that has been marked as end of life. End of life models cannot be used in any way. Collections or Tables that use the model must be recreated as data such as embeddings is not transferrable.
      
      The model is: ${model}. It is at ${modelStatus} status.
      ${message}
      
      Resend the command using supported model.

  - scope: SCHEMA
    code: CANNOT_VECTORIZE_UNKNOWN_COLUMNS
    title: Columns cannot be vectorized if they are not defined in the table schema
    body: |-
      The command attempted to vectorize columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to vectorize the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_VECTORIZE_NON_VECTOR_COLUMNS
    title: Columns cannot be vectorized if they are not `vector` type
    body: |-
      Columns can only be vectorized if they use the `vector` column type.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to vectorize the non-vector columns: ${nonVectorColumns}.
      
      Resend the command using only columns that use the `vector` type.

  - scope: SCHEMA
    code: CANNOT_DROP_VECTORIZE_FROM_UNKNOWN_COLUMNS
    title: Vectorize configuration cannot be dropped from columns if they are not defined in the table schema
    body: |-
      The command attempted to drop vectorize configuration from columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to drop vectorize configuration from the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_DROP_VECTORIZE_FROM_NON_VECTOR_COLUMNS
    title: Vectorize configuration cannot be dropped from columns if they are not `vector` type
    body: |-
      Columns can only have the vectorize configuration dropped if they use the `vector` column type.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to drop vectorize config from the non-vector columns: ${nonVectorColumns}.  
      
      Resend the command using only columns that use the `vector` type.

  - scope: SCHEMA
    code: LEXICAL_NOT_ENABLED_FOR_COLLECTION
    title: Lexical search is not enabled for the collection
    body: |-
      Lexical content can only be added and filtering and sort only be used on Collections for which Lexical feature is enabled.
      The Collection ${keyspace}.${table} does not have Lexical feature enabled.

  - scope: SCHEMA
    code: UNKNOWN_DATA_TYPE
    title: Data type is unknown
    body: |-
      The column definition used a data type that is not known.
        
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The supported data types are: ${supportedTypes}.
      The command used the unsupported data type: ${unsupportedType}.
      
      Resend the command using a known data types.

  - scope: SCHEMA
    code: UNKNOWN_PRIMITIVE_DATA_TYPE
    title: Primitive data type is unknown
    body: |-
      The column definition used the short hand for the data type, which only supports primitive data types.
            
      The supported primitive data types are: ${supportedTypes}.
      The command used the unsupported data type: ${unsupportedType}.
      
      Resend the command using a known primitive data type.

  - scope: SCHEMA
    code: UNSUPPORTED_DATA_TYPE_TABLE_CREATION
    title: Table creation with unsupported data types
    body: |-
      The column definition used unsupported data types for the table creation.
      
      The supported data types for table creation are: ${supportedTypes}.
      The command used the unsupported data types for table creation : ${unsupportedTypes}.
      
      Resend the command using supported data types for table creation.

  - scope: SCHEMA
    code: UNSUPPORTED_MAP_DEFINITION
    title: Map definition contains unsupported data types
    body: |-
      The command attempted to create a map column that used unsupported types for either the key or value.
      
      Maps can only use primitive type for the key and value with following exceptions:
      1. The key can't be duration, counter, timeuuid.
      2. The value can't be counter, timeuuid.
      
      The primitive data types are: ${supportedTypes}.
      The command used the key type: ${unsupportedKeyType}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported key and value type.

  - scope: SCHEMA
    code: UNSUPPORTED_LIST_DEFINITION
    title: List definition contains unsupported data types
    body: |-
      The command attempted to create a list column that used an unsupported type for the value.
      
      Lists can only use primitive type for the value, except for counter and timeuuid.
      
      The primitive data types are: ${supportedTypes}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported value type.

  - scope: SCHEMA
    code: UNSUPPORTED_SCHEMA_NAME
    title: The used schema name is not supported
    body: |-
      The command attempted to create a ${schemaType} with a name that is not supported.
      
      The supported ${schemaType} names must not be empty, more than ${maxNameLength} characters long, or contain non-alphanumeric-underscore characters.
      The command used the unsupported ${schemaType} name: '${unsupportedSchemaName}'.
      
      Resend the command using a supported ${schemaType} name.


  - scope: SCHEMA
    code: UNSUPPORTED_SET_DEFINITION
    title: Set definition contains unsupported data types
    body: |-
      The command attempted to create a set column that used an unsupported type for the value.
      
      Sets can only use primitive type for the value, except for counter and timeuuid.
      
      The primitive data types are: ${supportedTypes}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported value type.

  - scope: SCHEMA
    code: UNSUPPORTED_VECTOR_DIMENSION
    title: Vector definition contains unsupported dimension
    body: |-
      The command attempted to create a vector column that used an unsupported configuration.
      
      The dimension of the vector must be an positive integer value.
      
      The command used the dimension: ${unsupportedValue}.
      
      Resend the command using a supported vector dimension.

  - scope: SCHEMA
    code: UNKNOWN_INDEX_COLUMN
    title: Index column is not defined in the table schema
    body: |-
      The command attempted to create an index on a column that is not in the table schema.
      
      Indexes can only be created on existing columns.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: UNKNOWN_INDEX_TYPE
    title: Index type is unknown
    body: |-
      The command attempted to create an index using an unknown type.
      
      The known index types are: ${knownTypes}.
      The command used the unknown index type: ${unknownType}.
      
      Resend the command using a known index type.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEXING_FOR_DATA_TYPES
    title: Indexing not supported by data types
    body: |-
      The command attempted to create an index on a column that uses a data type not supported for indexing.
      
      Regular indexes can only be created on primitive data types such as `text` and `int`, collection data types such as 'map', 'set' and 'list', vector columns can be indexed using the createVectorIndex command.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The supported primitive data types are: ${supportedTypes}.
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of the supported data types.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEXING_FOR_FROZEN_COLUMN
    title: Index creation on a frozen column is not supported
    body: |-
      The command attempted to create an index on a column that is frozen.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The table has the frozen column: ${targetColumn}.
      
      Resend the command using the non-frozen column.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEX_TYPE
    title: Index type is not supported
    body: |-
      The command attempted to create an index using an unsupported type.
      
      The `indexType` field in the various `createIndex` commands is optional can be safely omitted. It is included in the output of `listIndexes` command to make it clear what type the indexes are, to make it clear which type of `createIndex` command can be used to re-create the index.
      
      The supported index types are: ${supportedTypes}.
      The command used the unsupported index type: ${unsupportedType}.
      
      Resend the command using a supported index type.    

  - scope: SCHEMA
    code: UNSUPPORTED_JSON_TYPE_FOR_TEXT_INDEX
    title: JSON value type is not supported for creating text index
    body: |-
      The command attempted to create a text index using an unsupported JSON value type.
      
      The supported JSON value types are: String, Object.
      The command used the unsupported JSON value type: ${unsupportedType}.
      
      Resend the command using a supported JSON value type.

  - scope: SCHEMA
    code: UNSUPPORTED_TEXT_ANALYSIS_FOR_DATA_TYPES
    title: Analysed text index not supported by data types
    body: |-
      The command attempted to create an index that specified text analysis on a column that uses a data type not supported for text analysis.
      
      Text analysis options `ascii`, `caseSensitive`, and `normalize` can be used on:
      1. primitive columns of type `text` or `ascii`
      2. list, set columns with value type `text` or `ascii`
      3. map columns with key type `text` or `ascii` when indexing on keys
      4. map columns with value type `text` or `ascii` when indexing on values
  
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns that support text analysis.

  - scope: SCHEMA
    code: UNSUPPORTED_TEXT_INDEX_FOR_DATA_TYPES
    title: Text index not supported by data types
    body: |-
      The command attempted to create a text index on a column that is not a `text` or `ascii` type.
      
      Text indexes can only be created on columns of type `text` or `ascii`.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to text index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of `text` type.
  

  - scope: SCHEMA
    code: UNSUPPORTED_VECTOR_INDEX_FOR_DATA_TYPES
    title: Vector index not supported by data types
    body: |-
      The command attempted to create a vector index on a column that is not a `vector` type.
      
      Vector indexes can only be created on columns of type `vector`, regular indexes can only be created on primitive data types such as `text` and `int` using the createIndex command.
      
      Note: Indexing for `map`, `list`, and `set` types will be added at a later date. 
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to vector index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of `vector` type.

  - scope: SCHEMA
    code: UNKNOWN_VECTOR_SOURCE_MODEL
    title: Vector source model is unknown
    body: |-
      The command attempted to create an vector index using a vector source model that is not known by the API.
      
      Including the optional name of the model that created the vectors when creating a vector index can provide significant performance improvements. 
      
      The known source models are: ${knownSourceModels}.
      The command attempted to use the source model: ${unknownSourceModel}.
      
      Resend the command using a known source model.

  - scope: SCHEMA
    code: UNKNOWN_VECTOR_METRIC
    title: Vector metric is unknown
    body: |-
      The command attempted to create an vector index using a metric that is not known by the API.
            
      The metric, also known as the similarity function, used to create the vector index is used to compare vectors to find the similar vectors.
      
      The known metrics are: ${knownMetrics}.
      The command attempted to use the metric: ${unknownMetric}.
      
      Resend the command using a known metric.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_INDEX
    title: Dropped index is not defined in the keyspace schema
    body: |-
      The command attempted to drop an index that is not in the keyspace schema.
      
      The command attempted to drop the unknown index: ${unknownIndex}.
      
      Resend the command using an index that exists in the keyspace.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_TABLE
    title: Dropped table is not defined in the keyspace schema
    body: |-
      The command attempted to drop a table that is not in the keyspace schema.
      
      The command attempted to drop the unknown table: ${unknownTable}.
      
      Resend the command using a table that exists in the keyspace.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_TABLE
    title: Table with the same name exists in the keyspace schema
    body: |-
      The command attempted to add a table that already exists in the keyspace schema.
      
      The command attempted to add the existing table: ${existingTable}.
      
      Resend the command using a table name that does not exist in the keyspace.

  - scope: SCHEMA
    code: CANNOT_ADD_UNSUPPORTED_DATA_TYPE_COLUMNS
    title: Alter table trying to add columns with unsupported data type
    body: |-
      The command attempted to add columns with unsupported data types to the table schema.
      
      The supported data types for adding columns are: ${supportedTypes}.
      The command attempted to add columns with unsupported data types: ${unsupportedTypes}.
      
      Resend the command using supported data types to alter table.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_INDEX
    title: Index with the same name exists in the keyspace schema
    body: |-
      The command attempted to add an index that already exists in the keyspace schema.
      
      The command attempted to add the existing index: ${existingIndex}.
      
      Resend the command using an index name that does not exist in the keyspace.

    # prev errors - all need to be reviewed

  - scope: SCHEMA
    code: INVALID_INDEX_DEFINITION
    title: Provided index configuration is not valid.
    body: |-
      Provided index configuration is not valid: ${reason}.

  - scope: SCHEMA
    code: INVALID_KEYSPACE
    title: Keyspace used is not valid.
    body: |-
      Keyspace used is not valid: ${keyspace} 

  - scope: SCHEMA
    code: COLUMN_TYPE_INCORRECT
    title: Column data type not provided or format invalid in the definition
    body: |-
      Column data type not provided or format invalid in the definition.
      Column definition can be defined in shorthand format as: 
        "column_name": "text"
      
      or in nested object structure format as:
        "column_name": {
          "type": "text"
        }

  - scope: SCHEMA
    code: PRIMARY_KEY_DEFINITION_INCORRECT
    title: Primary key definition provided is incorrect.
    body: |-
      Primary key definition provided is incorrect.
      1. A single primary key column can be defined using the shorthand format as:
        "primaryKey": "id"
      2. A composite primary key can be defined using the advanced nested object structure format as:
        "primaryKey": {
          "partitionBy": [
            "id"
          ],
          "partitionSort": {
            "name" : 1, "age" : -1
          }
        }
        Following are checked as part of composite primary keys:
          a. partitionBy is mandatory.
          b. partitionSort is optional.
          c. partitionSort should not have the columns defined in partitionBy.
          d. partitionSort values should be either `1` for ascending or `-1` for descending.

  - scope: SCHEMA
    code: INVALID_CONFIGURATION
    title: Unable to parse configuration, schema invalid.
    body: |-
      Unable to parse configuration, schema invalid.

  - scope: SCHEMA
    code: INVALID_FORMAT_FOR_INDEX_CREATION_COLUMN
    title: Unable to create index, format for index creation column is invalid.
    body: |-
      Command has an invalid format for index creation column.
      
      The column string can have different formats:
      - Primitive column: {"column": "primitiveColumn"}
      - List column: {"column": "listColumn"}
      - Set column: {"column": "setColumn"}
      - Map column:
        - Default to index on map entries: {"column": "mapColumn"}
        - Index on map keys: {"column": {"mapColumn" : "$keys"}}
        - Index on map values: {"column": {"mapColumn" : "$values"}}
      
      Resend the command using a valid format for index creation column.

  - scope: SCHEMA
    code: INVALID_VECTORIZE_CONFIGURATION
    title: Unable to parse vectorize configuration, schema invalid.
    body: |-
      Unable to parse vectorize configuration, schema invalid for field ${field}.

  - scope: SCHEMA
    code: COLUMN_NOT_FOUND
    title: Column doesn't exist in the table.
    body: |-
      Column `${column}` doesn't exist in the table.

# ================================================================================================================
# Family: REQUEST         Scope: SORT
# ================================================================================================================

  - scope: SORT
    code: CANNOT_SORT_ON_MULTIPLE_VECTORS
    title: More than one vector sort provided
    body: |-
      The command used a sort clause with more than one vector sort, only one vector sort is allowed.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to vector sort on the columns: ${sortColumns}.
      
      Resend the command with only one vector sort.

  - scope: SORT
    code: CANNOT_SORT_ON_MULTIPLE_VECTORIZE
    title: More than one vectorize sort provided
    body: |-
      The command used a sort clause with more than one vectorize sort, only one vectorize sort is allowed. 

      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to vectorize sort on the columns: ${sortColumns}.
      
      Resend the command with only one vectorize sort.

  - scope: SORT
    code: CANNOT_SORT_UNKNOWN_COLUMNS
    title: Sorted columns are not defined in the table schema
    body: |-
      The command attempted to sort using columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to sort the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns that are defined in the table schema.

  - scope: SORT
    code: OVERLOADED_SORT_ROW_LIMIT
    title: Sort aborted due to in memory sort restriction
    body: |-
      The command used in memory sorting which has a limit of 10,000 rows. 
      
      Consult any warnings included in the response for how to improve the sort performance.
      
      Resend the command using a more specific filter to reduce the number of rows sorted.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_NON_VECTOR_COLUMNS
    title: Vector sort columns are not `vector` type
    body: |-
      The command attempted to vectorize sort on a column that is not of `vector` type.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the columns: ${vectorColumns}.
      The command attempted to sort the non vector columns: ${sortColumns}.  
      
      Resend the command using only `vector` columns.

  - scope: SORT
    code: CANNOT_VECTORIZE_SORT_NON_VECTOR_COLUMN
    title: Vectorize sort columns are not `vector` type
    body: |-
      The command attempted to vectorize sort on a column that is not of `vector` type.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines vector columns: ${vectorColumns}.
      The command attempted to sort the non-vector columns: ${sortColumns}.
      
      Resend the command using only `vector` columns with vectorize enabled.

  - scope: SORT
    code: CANNOT_VECTORIZE_SORT_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize sort not supported on column with missing vectorize configuration
    body: |-
      Vectorize sort can only be used with columns that have a vectorize configuration. 
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize definition: ${validVectorizeColumns}.
      The command included the following vector columns without vectorize definition: ${invalidVectorizeColumns}.
      
      Resend the command using only `vector` columns with a vectorize definition.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_WITH_LIMIT_EXCEEDS_MAX
    title: Limit exceeds the maximum allowed for vector sort
    body: |-
        The command attempted to vector sort columns with a limit that exceeds the maximum allowed.
        
        Vector sorting is limited to a maximum of ${maxLimit} rows.
        The command attempted to sort the vector column: ${sortColumn} with a limit of ${limit}.
        
        Resend the command using a limit of ${maxLimit} or less.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_WITH_SKIP_OPTION
    title: Skip option cannot be used with  vector sort
    body: |-
      The command attempted to vector sort columns along with skip option set. 
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      Resend the command without the skip option.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_NON_INDEXED_VECTOR_COLUMNS
    title: Vector sort cannot be used for non indexed vector columns
    body: |-
      The command attempted to vector sort vector columns that are not indexed.
      
      Vector sorting is only supported on vector columns that have been indexed.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      And has indexes on the vector columns: ${indexedColumns}.
      The command attempted to sort vector columns: ${sortColumns}.  
      
      Resend the command using only indexed vector columns.

  - scope: SORT
    code: CANNOT_SORT_VECTOR_AND_NON_VECTOR_COLUMNS
    title: Vector sort cannot be used with non vector sorting
    body: |-
      The command attempted to vector sort vector columns and other non vector columns.
      
      Vector sorts must use a single vector column, and cannot include any other sort columns.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to sort the vector columns: ${sortVectorColumns}.
      The command attempted to sort the non-vector columns: ${sortNonVectorColumns}.
      
      Resend the command using either vector or non-vector sorting.

  - scope: SORT
    code: UNSUPPORTED_SORT_FOR_TABLE_DELETE_COMMAND
    title: Sorting not supported by delete command on Tables
    body: |-
      The command attempted to sort a delete command running against a table. 

      Deleting rows in a table does not support sorting, rows can only be deleted by specifying the partition key(s) and optionally the clustering key(s) for the row(s) to be deleted.
      
      Resend the command without the sort clause.

  - scope: SORT
    code: UNSUPPORTED_SORT_FOR_TABLE_UPDATE_COMMAND
    title: Sorting not supported by update command on Tables
    body: |-
      The command attempted to sort a update command running against a table. 

      Updating row in a table does not support sorting, a row can only be updated by specifying full primary key(s).
      
      Resend the command without the sort clause.

  - scope: SORT
    code: UNSUPPORTED_PAGINATION_WITH_IN_MEMORY_SORTING
    title: Pagination not supported when using in-memory sorting
    body: |-
      Pagination is not supported when the data is sorted in-memory.

      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The command sorted on the columns: ${sortColumns}.
      
      Resend the command without pagination.    

  - scope: SORT
    code: UNSUPPORTED_VECTOR_SORT_FOR_COLLECTION
    title: Vector sorting not supported by the Collection
    body: |-
      The command attempted to vector sort against a Collection that does not have vectors enabled. 

      Vector sorting is enabled when creating a collection via the `vector` configuration option. It must be defined at creation time as all vectors have the same dimension.
      
      The Collection ${keyspace}.${table} does not have vectors enabled.
      
      Resend the command using a Collection with vectors enabled, or create a new Collection.


  - scope: SORT
    code: UNSUPPORTED_VECTORIZE_SORT_FOR_COLLECTION
    title: Vectorize sorting not supported by the Collection
    body: |-
      The command attempted to vectorize sort against a Collection that does not have vectorize enabled. 

      Vectorize allows the Collection to calculate the sort vector for a text value server side. Vectorize is enabled when creating a collection via the `vector` configuration option, it must be defined at creation time as all vectors have the same dimension and model.
      
      The Collection ${keyspace}.${table} does not have vectorize enabled.
      
      Resend the command using a Collection with vectorize enabled, or create a new Collection.
# ================================================================================================================
# ================================================================================================================
#                                           Server Errors
# ================================================================================================================
# ================================================================================================================

server-errors:
  # UNSCOPED server errors
  - scope:
    code: UNEXPECTED_SERVER_ERROR
    title: Unexpected server error
    body: |-
      An unexpected server error occurred while processing the request. 
      
      Error Class: ${errorClass}
      Error Message: ${errorMessage}
      
      ${SNIPPET.RETRY_UNKNOWN}

  # DATABASE scope server errors
  - scope: DATABASE
    code: UNEXPECTED_DRIVER_ERROR
    title: Unexpected driver error
    body: |-
      An unexpected server error occurred while using the driver with the database. 
      
      The command against the ${schemaType} ${keyspace}.${table} may be in an inconsistent state due to the error encountered. It may have either: 
      * Failed to start communicating with the database.
      * Encountered an error when being processed by the database.
      * Completed successfully, but returned an unexpected response.
      
      Consult the the detailed error message below for more information:
      
      Error Class: ${errorClass}
      Error Message: ${errorMessage}
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    # NOTE: this is here as a server error because the API should have caught missing keyspace before sending to the database
    code: UNKNOWN_KEYSPACE
    title: Unknown keyspace
    body: |-
      The command referenced a keyspace that does not exist in the database. 
      
      The Data API believed the keyspace existed, but the database returned an error that the keyspace does not exist. This may be a temporary issue.
      
      The command used the keyspace: ${keyspace}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_TO_CONNECT_TO_DATABASE
    title: Data API Failed to connect to the database
    body: |-
      The Data API was unable to connect to any nodes in the database to process the command. 
      
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: UNAUTHORIZED_ACCESS
    title: Unauthorized access to the database
    body: |-
      The command is not authorized to perform the action on the database. 
      
      The authentication details provided with the command do not allow it to perform the action is was attempting, such as reading or writing data. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      
      Resend the command using the correct authentication details.

  - scope: DATABASE
    code: INVALID_DATABASE_QUERY
    title: Invalid database query
    body: |-
      The Data API command generated a database query that while syntactically correct, was rejected as invalid by the database.  
      
      The Data API should have generated a valid query, or returned an error before sending the query to the database. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      Retrying the command will likely result in the same error.

  - scope: DATABASE
    code: UNSUPPORTED_DATABASE_QUERY
    title: Unsupported database query
    body: |-
      The Data API command generated a database query that was syntactically incorrect, and was rejected by the database.  
      
      The Data API should should only generate correct database syntax. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      Retrying the command will likely result in the same error.

  - scope: DATABASE
    code: FAILED_COMPARE_AND_SET
    title: Failed database Compare and Set operation
    body: |-
      The Data API command generated a database query that used the Compare and Set feature, and the database was unable to determine if the operation was successful.    
      
      This should be a rare error, and may be due to a temporary capacity issue with the database. The API uses idempotent operations when modifying Documents in Collections which removes the possibility of data corruption.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_TRUNCATION
    title: Failed database Truncate operation
    body: |-
      The Data API command generated a database query to truncate the table, and the database was either unable to start or complete the operation.     
      
      Truncating a Collection or Table requires that all worker nodes in the Keyspace are available, and complete the operation in the required time. Completing the operation includes flushing memory to disk, and snapshotting on disk files. 
      
      This is operation has the lowest level of availability as all nodes must be involved. And so it may fail while other read and write operations success, as they do not require all nodes to be available. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: UNAVAILABLE_DATABASE
    title: The database is unavailable
    body: |-
      The Data API submitted a query to the database, but the database refused to start processing as not enough nodes available.      
      
      Queries typically require 2 out of 3 replicas to be available before they can start, though the exact numbers can vary. And the random distribution of data allows for some queries to have enough replicas, while other do not (known as partial availability).   
      
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The number of nodes required was: ${requiredNodes}.
      The number of nodes available was: ${aliveNodes}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_READ_REQUEST
    title: Failed database request
    body: |-
      The Data API command generated a database query that was syntactically correct and the database started processing, however too many nodes failed to complete the operation.     
      
      This error indicates an issue processing the request, not that the request timed out before completing. 
            
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The number of nodes that failed was: ${failedNodes}.
      The data was returned to the coordinator node was: ${dataPresent}
      The unique set of node failures reasons was: ${failureReasons}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_WRITE_REQUEST
    title: Failed database request
    body: |-
      The Data API command generated a database query that was syntactically correct and the database started processing, however too many nodes failed to complete the operation.     
      
      This error indicates an issue processing the request, not that the request timed out before completing. 
      
      When working with Collections the data will be consistent, even when failing to write data. When working with Tables the data may be in an Eventually Consistent state, as the operation may have completed on some replicas, but not all.
      
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The number of nodes that failed was: ${failedNodes}.
      The write type was: ${writeType}.
      The unique set of node failures reasons was: ${failureReasons}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: TIMEOUT_READING_DATA
    title: Timeout reading data from the database
    body: |-
      The Data API generated a database query that timed out before completing the operation.
      
      The query was most likely correct, but not enough nodes confirmed the operation had completed before the timeout.
            
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The data was returned to the coordinator node was: ${dataPresent}
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: TIMEOUT_WRITING_DATA
    title: Timeout writing data to the database
    body: |-
      The Data API generated a database query that timed out before completing the operation.
      
      The query was most likely correct, but not enough nodes confirmed the operation had completed before the timeout.
      
      For Collections that data will be consistent. When working with Tables the data may be in an Eventually Consistent state, as the operation may have completed on some replicas but not all, which can result in inconsistent reads.
      
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The write type was: ${writeType}.
      
      ${SNIPPET.RETRY}

  # EMBEDDING scope server errors
  - scope: EMBEDDING_PROVIDER
    code: CLIENT_ERROR
    title: The Embedding Provider returned a HTTP client error
    body: |-
      Provider: ${provider}; HTTP Status: ${httpStatus}; Error Message: ${errorMessage}

  - scope: EMBEDDING_PROVIDER
    code: SERVER_ERROR
    title: The Embedding Provider returned a HTTP client error
    body: |-
      Provider: ${provider}; HTTP Status: ${httpStatus}; Error Message: ${errorMessage}