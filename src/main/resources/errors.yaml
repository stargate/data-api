# Data API Error Objects
#
# This file contain the error messages that are returned by the Data API
#
# The error descriptions in this file are ready by the APIException classes to create the content for the errors.
# That is, only errors defined in the code are read from this file, see the APIException class in the code
# for a description of how the errors are defined and manged.
#
# Errors have the following hierarchy:
# Family -> (optional) Scope -> Code
#
# Where
# * Family: Identifies if the error relates to the client request or the server processing, analogous
#           to the 4XX and 5XX HTTP status codes. Supported values are REQUEST or SERVER. In this file they are
#           represented by the request-errors and server-errors keys.
# * Scope: Optionally identifies the part of the request or server processing that caused the fault, for example "FILTER"
#          when there is a problem in the filter clause. Scope generally map to a concrete APIException class such as
#          FilterException.
# * Code: A unique string identifying the error.
#
# All values are strings and must be UPPER_SNAKE_CASE_1 supporting upper case alpha and digits.
#
# FILE LAYOUT
# ===========
#
# "snippets" is a list of text snippets than can be included in any error body, the snippets are included in the
# variables when running the template for the body of the error. Snippets are referenced using `${SNIPET.<NAME>}`
# variables when running the template for the body of the error. Snippets are referenced using `${SNIPET.<NAME>}`
# where <NAME> is the name of the snippet key.
# Each snippet has:
# - name: UPPER_SNAKE_CASE_1
# - body: A string with the text of the snippet, recommend using the `|-` to trim trailing newlines.
#
# "request-errors" and "server-errors" are lists of error objects, for the REQUEST and SERVER family respectively.
# Each error object has:
# - scope: UPPER_SNAKE_CASE_1
# - code: UPPER_SNAKE_CASE_1
# - http-status-override: (optional) The HTTP status code to return when this error is thrown. If not present, the
#                           default status code is 200 for most things. This is not returned in the error object JSON
#                           It is used to override the HTTP status code in the response.
#                           NOTE: NO checking is done to confirm this is a valid HTTP status code.
# - title: A short title for the error, that must not change between instances of the error.
# - body: A longer body that may contain ${vars} to be passed by the code when created, and references to snippets.
#         This can be a multi line string, recommend using the `|-` to trim trailing newlines.
#
# NOTE: Please keep the entries sorted on their name for snippets, or scope and code for errors. Please add a
#       new line after each entry, using the `|-` to trim trailing newlines.

# ================================================================================================================
# ================================================================================================================
#                                           SNIPPETS
# ================================================================================================================
# ================================================================================================================

snippets:
  - name: RETRY
    body: |-
      It is safe to retry this request.

  - name: RETRY_AFTER_FIX
    body: |-
      Fix the issue before retrying this request.

  - name: RETRY_UNKNOWN
    body: |-
      Review the Error Message before retrying this request.

  - name: INEFFICIENT_FILTER
    body: |-
      The query was executed without taking advantage of the primary key or indexes on the table, this can have performance implications on large tables.
      
      See documentation for best practices for filtering.

  - name: INEFFICIENT_SORT
    body: |-
      The command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.
      
      See documentation for best practices for sorting.

  - name: RESEND_USING_ONLY_DEFINED_COLUMNS
    body: |-
      Resend the command using only defined columns.

  - name: REGULAR_SORT_EXPLANATION
    body: |-
      A regular sort expression in the sort clause identifies the column by name and then provides either:  
      - `1` for ascending
      - `-1` for descending

  - name: LEXICAL_SORT_EXPLANATION
    body: |-
      A lexical sort expression in the sort clause identifies the column by name and then provides:
      - String to use for lexical matching to sort by (most similar first)

  - name: VECTOR_SORT_EXPLANATION
    body: |-
      A vector sort in the sort clause identifies the vector column by name and then provides either:  
      - The vector as an array of decimal numbers.
      - The vector as a base64-encoded `{"$binary": "base64-encoded-vector"}` object.
      - A string to be vectorized if enabled for the column.

  - name: CURRENTLY_UNSUPPORTED
    body: |-
      Currently API tables have limited support for: 
      
      - Cassandra `timeuuid`, `counter` types.
      - Tuple types.
      - Filtering and indexing on Cassandra collection types `list`, `map`, `set`.
      - Defining `maps`, `list`, or `set` columns using any key type other than `text` or `ascii`.
      
      Support for these features will be expanded in future releases.

  - name: ADD_VECTORIZE_CONFIG
    body: |-
      Vectorize configuration can be added when the table is created or later using the `alterTable` command.

  - name: EXPLAIN_PARTITIONING
    body: |-
      Rows in API tables are partitioned by the partition key, which can be one or more columns. All rows in the same partition share the same partition key values and can be very quickly read in the order of the partition sorting.




# ================================================================================================================
# ================================================================================================================
#                                           REQUEST Errors
# ================================================================================================================
# ================================================================================================================

# ================================================================================================================
# Family: REQUEST         Scope: NONE
# ================================================================================================================

request-errors:
  # UNSCOPED request errors

  - scope:
    code: COMMAND_ACCEPTS_NO_OPTIONS
    title: Command accepts no options
    body: |-
      Command '${command}' does not accept options but some were included.
      
      Resend command without options.

  - scope:
    code: COMMAND_FIELD_VALUE_INVALID
    title: Command field value invalid
    body: |-
      Command field '${field}' value ${value} not valid: ${message}.
      
      Resend command with valid value.

  - scope:
    code: COMMAND_FIELD_UNKNOWN
    title: Command field unknown
    body: |-
      Command field '${field}' not recognized: ${message}.
      
      Resend command with valid command fields.

  - scope:
    code: COMMAND_UNKNOWN
    title: Command is not recognized by Data API
    body: |-
      Command '${command}' is not a ${commandType} recognized by Data API.
      
      Data API supports following ${commandType}s: ${knownCommands}.
      
      Resend using one of the supported commands.

  - scope:
    code: HYBRID_FIELD_CONFLICT
    title: Conflict with $hybrid field
    body: |-
      Field '$hybrid' cannot be used with '$lexical', '$vector', or '$vectorize'.
      
      Resend command without conflicting fields.

  - scope:
    code: HYBRID_FIELD_UNSUPPORTED_VALUE_TYPE
    title: Unsupported JSON value type for $hybrid field
    body: |-
      Unsupported JSON value type for '$hybrid' field: ${errorMessage}.

  - scope:
    code: HYBRID_FIELD_UNKNOWN_SUBFIELDS
    title: Unknown sub-field(s) for $hybrid field
    body: |-
      Unknown sub-field(s) for '$hybrid' field: ${errorMessage}.

  - scope:
    code: HYBRID_FIELD_UNSUPPORTED_SUBFIELD_VALUE_TYPE
    title: Unsupported JSON value type for $hybrid sub-field
    body: |-
      Unsupported JSON value type for '$hybrid' sub-field: ${errorMessage}.

  - scope:
    code: INVALID_CREATE_COLLECTION_FIELD
    title: Invalid field(s) for createCollection
    body: |-
      'createCollection' command referenced unrecognized field(s): ${message}
      
      Resend 'createCollection' with only valid fields.

  - scope:
    code: REQUEST_NOT_JSON
    title: Request not valid JSON
    body: |-
      Request not valid JSON, problem: ${errorMessage}.
      
      Resend request as valid JSON.

  - scope:
    code: REQUEST_STRUCTURE_MISMATCH
    title: Request structure not valid
    body: |-
      Request is valid JSON but has a structural mismatch: ${errorMessage}.
      
      Resend request with valid structure.

  - scope:
    code: UNSUPPORTED_CONTENT_TYPE
    http-status-override: 415
    title: Unsupported Content-Type
    body: |-
      Request sent with unsupported 'Content-Type' header value.
      
      The API only supports content type: application/json
      
      Resend with supported 'Content-Type' header.

  - scope:
    code: UNSUPPORTED_TABLE_COMMAND
    title: Command is not supported by tables
    body: |-
      The command is not supported by tables in the API.  
      
      While many commands operate on both tables and collections, some commands can only be run against tables or collections. 
      
      The commands supported by tables are: ${tableCommands}.
      The commands supported by collections are: ${collectionCommands}.
      
      The unsupported command ran against the table: ${keyspace}.${table}
      The unsupported command was: ${unsupportedCommand}.
      
      Resend using one of the supported commands.

  - scope:
    code: UNSUPPORTED_COLLECTION_COMMAND
    title: Command is not supported by collections
    body: |-
      The command is not supported by collections in the API.  
      
      While many commands operate on both tables and collections, some commands can only be run against tables or collections. 
      
      The commands supported by collections are: ${collectionCommands}.
      The commands supported by tables are: ${tableCommands}.
      
      The unsupported command ran against the collection: ${keyspace}.${table}
      The unsupported command was: ${unsupportedCommand}.
      
      Resend using one of the supported commands. 

  - scope:
    code: UNSUPPORTED_RERANKING_COMMAND
    title: Reranking not enabled for collection
    body: |-
      The `findAndRerank` is not enabled for the collection.
      
      The Command is only supported for collections that have `vector`, `lexical`, and `rerank` configured. They additionally require a vectorize configuration if `$vectorize` is used.
      
      Resend using a supported collection. 

  # unscoped because this touches both the sort and the options
  - scope:
    code: MISSING_RERANK_QUERY_TEXT
    title: Rerank query text is missing
    body: |-
      The findAndRerank command is missing the text to use as the query with the reranking model.

      Reranking involves using a model to compare passages of text to a user query. 
      
      The query can be specified using either: 
      * `$hybrid` field in the sort clause, e.g. `{"$hybrid": "query text"}`.
      * `$vectorize` field in the sort clause, when using different sorting for vectorize and lexical, e.g. `{"$hybrid":  {"$vectorize": "query text"}}`.
      * `rerankQuery` field in the options clause, e.g. `{"rerankQuery": "query text"}`.
      
      When specified the `rerankQuery` option takes priority. In all cases the query text must be a non blank text value. 
      
      Resend the command including the query text for reranking.

  # ================================================================================================================
  # Family: REQUEST         Scope: SECURITY
  # ================================================================================================================

  - scope: SECURITY
    http-status-override: 401
    code: MISSING_AUTHENTICATION_TOKEN
    title: Missing authorization token
    body: |-
      The command did not include an authorization token in the request headers.
      
      The authorization header is: ${authHeader}.
      
      Resend the command using the correct authentication details.

  - scope: SECURITY
    http-status-override: 401
    code: UNAUTHORIZED_ACCESS
    title: Unauthorized access to the database
    body: |-
      The command is not authorized to perform the action on the database. 
      
      The authentication details provided with the command do not allow it to perform the action is was attempting, such as reading or writing data. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      
      Resend the command using the correct authentication details.

  - scope: SECURITY
    http-status-override: 401
    code: UNAUTHENTICATED_REQUEST
    title: Authentication failed
    body: |-
      Authentication failed for request due to invalid token.
      
      Resend with valid authentication token.


# ================================================================================================================
# Family: REQUEST         Scope: DOCUMENT
# ================================================================================================================

 # DOCUMENT request errors
  - scope: DOCUMENT
    code: DOCUMENT_ALREADY_EXISTS
    title: Document the given _id already exists
    body: |-
      Cannot insert the document: a document already exists with given '_id' (${id}). 

      Either resend the command with distinct '_id', or use an update command instead.

  - scope: DOCUMENT
    code: DOCUMENT_REPLACE_DIFFERENT_DOCID
    title: Document the given _id already exists
    body: |-
      The replace document and document resolved using filter have different '_id's: ${replaceId} (replace document) vs. ${matchedId} (document that filter matches). 

      Resend the update command with a document that has same '_id' as document being replaced.

  - scope: DOCUMENT
    code: INVALID_VECTORIZE_VALUE_TYPE
    title: Invalid $vectorize value type
    body: |-
      Invalid $vectorize value: ${errorMessage}.

  - scope: DOCUMENT
    code: MISSING_PRIMARY_KEY_COLUMNS
    title: Primary key columns missing
    body: |-
      All primary key columns must be provided when inserting a document into a table. 
      
      The table ${keyspace}.${table} defines the primary key columns: ${primaryKeys}.
      
      The command included values for primary key columns: ${providedKeys}.
      The command did not include values for primary key columns: ${missingKeys}.
      
      Resend the command including the missing primary key columns.

  - scope: DOCUMENT
    code: SHRED_BAD_BINARY_VECTOR_VALUE
    title: Bad binary vector value to shred
    body: |-
      Bad binary vector value to shred: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_DOCID_TYPE
    title: Bad type for '_id' field
    body: |-
      Bad type for '_id' field: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_DOCID_VALUE
    title: Bad value for '_id' field
    body: |-
      Bad value for '_id' field: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_DOCUMENT_TYPE
    title: Bad document type to shred
    body: |-
      Bad document type to shred: document must be a JSON Object, instead got a JSON ${documentType}.

  - scope: DOCUMENT
    code: SHRED_BAD_DOCUMENT_VECTOR_TYPE
    title: Bad $vector value to shred
    body: |-
      Bad $vector value to shred: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_DOCUMENT_LEXICAL_TYPE
    title: Bad $lexical value to shred
    body: |-
      Bad $lexical value to shred: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_EJSON_VALUE
    title: Bad JSON Extension value to shred
    body: |-
      Bad JSON Extension value to shred: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_FIELD_NAME
    title: Document field name not valid
    body: |-
      Document field name not valid: ${errorMessage}.

  - scope: DOCUMENT
    code: SHRED_BAD_VECTOR_SIZE
    title: Bad $vector value
    body: |-
      Bad $vector value: cannot be empty Array.

  - scope: DOCUMENT
    code: SHRED_BAD_VECTOR_VALUE
    title: Bad $vector value
    body: |-
      Bad $vector value: needs to be an array containing only Numbers but has a ${nodeType} value (${nodeValue}).

  - scope: DOCUMENT
    code: SHRED_DOC_LIMIT_VIOLATION
    title: Document size limitation violated
    body: |-
      Document size limitation violated: ${errorMessage}.

  # NOTE: UNKNOWN_TABLE_COLUMNS is also in the FILTER scope
  - scope: DOCUMENT
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in documents are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be included when inserted a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: DOCUMENT
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in documents are not supported
    body: |-
      Only supported column types can be included when inserting a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.

  - scope: DOCUMENT
    code: INVALID_COLUMN_VALUES
    title: Column values in documents are not valid
    body: |-
      Only values that are supported by the column data type can be included when inserting a document into a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that had invalid values: ${invalidColumns}.
      
      Resend the command using only supported column values.

  - scope: DOCUMENT
    code: UNSUPPORTED_VECTORIZE_CONFIGURATIONS
    title: Unsupported combination of vectorize configurations
    body: |-
      A request can include only one unique combination of provider, model, and dimension for vectorization.
      
      The following combinations were included in your request: ${vectorizeIdentities}.
      
      Resend the command using only one unique combination of provider, model, and dimension for vectorization.
      
      Support for these features will be expanded in future releases.

  - scope: DOCUMENT
    code: UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize not supported on column with missing vectorize configuration
    body: |-
      Vectorize can only be used with columns that have a vectorize configuration. 
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize definition: ${validVectorizeColumns}.
      The command included the following vector columns without vectorize definition: ${invalidVectorizeColumns}.
      
      Resend the command using only vector columns with a vectorize definition.

  - scope: DOCUMENT
    code: UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize not supported on column with missing vectorize configuration
    body: |-
      Vectorize can only be used with columns that have a vectorize configuration. 
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize definition: ${validVectorizeColumns}.
      The command included the following vector columns without vectorize definition: ${invalidVectorizeColumns}.
      
      Resend the command using only vector columns with a vectorize definition.

  - scope: DOCUMENT
    code: LEXICAL_CONTENT_TOO_LONG
    title: Lexical content exceeds maximum length
    body: |-
      The command attempted to insert or update the `$lexical` field with content that exceeds the maximum allowed length. 
      
      The collection: ${keyspace}.${table}.
      
      Resend the command using a smaller value for the `$lexical` field.

  - scope: DOCUMENT
    code: INVALID_VECTOR_LENGTH
    title: Vector values in documents are not valid
    body: |-
      The command attempted to update or find using `$vector`, using a vector that has a length different to the declared '$vector' dimension for the Collection.
      
      The collection was: ${keyspace}.${table}.
      The configured vector dimension is: ${configVectorLength}.
      
      Resend the command using a vector of the correct length.

# ================================================================================================================
# Family: REQUEST         Scope: FILTER
# ================================================================================================================

  - scope: FILTER
    code: CANNOT_LEXICAL_FILTER_NON_INDEXED_COLUMNS
    title: Lexical filter cannot be used for non-indexed columns
    body: |-
      The command attempted to lexical filter on column that is not text-indexed.
      
      Lexical filtering is only supported on columns that have been text-indexed.
      
      The table ${keyspace}.${table} has text indexes on columns: ${indexedColumns}.
      The command attempted to filter column(s): ${filterColumns}.
      
      Resend the command using indexed column(s).

  - scope: FILTER
    code: FILTER_FIELDS_LIMIT_VIOLATION
    title: Filter fields size limitation violated
    body: |-
      Filter has ${fieldCount} fields, exceeds maximum allowed (${maxFieldCount}).
      
      Resend the command with filter that does not exceed maximum field count.

  - scope: FILTER
    code: FILTER_ID_NOT_INDEXED
    title: Collection field '_id' not indexed can only filter with '$eq' or '$in'
    body: |-
      Collection field '_id' is never indexed so filtering can only be done using operators '$eq' or '$in', not '${operator}'.
      
      Resend the command with proper filter.

  - scope: FILTER
    code: FILTER_INVALID_EXPRESSION
    title: Unsupported filter clause
    body: |-
      Unsupported filter clause: ${message}.
      
      Resend the command using only supported filter expressions and paths.

  - scope: FILTER
    code: FILTER_MULTIPLE_ID_FILTER
    title: Can only have one '_id' equals filter clause
    body: |-
      Command included more than one '_id' equals filter clauses, which is not supported: use '$in' operator instead.
      
      Resend the command using supported filters.

  - scope: FILTER
    code: FILTER_PATH_UNINDEXED
    title: Collection path used in filter clause not indexed
    body: |-
      Collection path '${path}' is not indexed: cannot filter on that path.
      
      Resend the command with filter clause without such paths.

  - scope: FILTER
    code: FILTER_UNSUPPORTED_DATA_TYPE
    title: Unsupported filter data type
    body: |-
      Unsupported filter data type: ${message}.

      Resend the command using supported filter data types.

  - scope: FILTER
    code: FILTER_UNSUPPORTED_OPERATOR
    title: Unsupported filter operator
    body: |-
      Unsupported ${message}.

      Resend the command using only supported operators.

  # NOTE: UNKNOWN_TABLE_COLUMNS is also in the DOCUMENT scope
  - scope: FILTER
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the filter are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be filtered on.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The filter included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: FILTER
    code: INVALID_FILTER_COLUMN_VALUES
    title: Column value in filter is not valid
    body: |-
      Only values that are supported by the column data type can be included when filtering.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the column ${invalidColumn} that has ${columnType} type defined.
      
      Resend the command using only supported column values.

  - scope: FILTER
    code: INVALID_MAP_SET_LIST_FILTER
    title: Command has invalid filter against a map, set, or list column
    body: |-
      Command has an invalid filter, ${detailedReason}.
      
      Supported filter operators for map, set, list are '$in', '$nin', '$all'.
      Filter examples for map column:
      - filter on map keys {"mapColumn": {"$keys": {"$in": ["key1", "key2"]}}}
      - filter on map values {"mapColumn": {"$values": {"$nin": ["value1", "value2"]}}}
      - filter on map entries {"mapColumn": {"$all": [["key1", "value1"], ["key2", "value2"]]}}
      Filter examples for list column:
      - filter on list {"listColumn": {"$in": ["value1", "value2"]}}}
      Filter examples for set column:
      - filter on set {"setColumn": {"$nin": ["value1", "value2"]}}}
      
      Resend the command using correct filter.

  - scope: FILTER
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in the filter are not supported
    body: |-
      Only column types supported by the API can be filtered on.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.  

  - scope: FILTER
    code: UNSUPPORTED_FILTERING_FOR_COLUMN_TYPES
    title: Column types in the filter do not support the filter operations
    body: |-
      Filtering is only supported on primitive data types such as `text` not on container types such as `list`, `set`, `map`, or `vector`.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included unsupported filters on the columns: ${complexColumns}.
      
      Resend the command using only supported column types.  

  - scope: FILTER
    code: UNSUPPORTED_COMPARISON_FILTER_AGAINST_DURATION
    title: Duration data type does not support comparison filters
    body: |-
      Filtering using the comparison operations ($lt, $gt, $lte, $gte) is not supported against `duration` column types.
    
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request used a comparison operation on duration columns: ${durationFilters}.
      
      Resend the command using only supported operations on `duration` columns. 

  - scope: FILTER
    code: MISSING_FILTER_FOR_UPDATE_DELETE
    title: Update and delete commands require a filter
    body: |-
      Update and delete commands for tables require a filter.
      
      These commands require a filter that identifies a either a single row (for `updateOne` and `deleteOne`) or a partition and a sequence of rows (for `deleteMany`). 
      
      Note: using the `deleteMany` command without a filter truncates all rows from the table.
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeyColumns}.
      
      Resend the command using a filter.

  - scope: FILTER
    code: UNSUPPORTED_FILTER_FOR_UPDATE_ONE_DELETE_ONE
    title: updateOne and deleteOne commands only support filtering using $eq
    body: |-
      The Filtering using the non `$eq` filter operations can select more than one row, and so cannot be used with the `updateOne` and `deleteOne` commands as they can only modify one row.
      
      The command used an invalid filter on the columns: ${unsupportedFilterColumns}.
      
      Resend the command only using `$eq` filters.

  - scope: FILTER
    code: UNSUPPORTED_NON_PRIMARY_KEY_FILTER_FOR_UPDATE_DELETE
    title: Update and delete commands only support filtering on the primary key
    body: |-
      The Update or delete commands can only filter using columns that are part of the primary key.
      
      The table ${keyspace}.${table} defines the primaryKeys: ${primaryKeyColumns}.
      The filter used the non primary key columns: ${nonPrimaryKeyFilters}
      
      Resend the command using with a filter that only uses the primary key columns.

  - scope: FILTER
    code: MISSING_FULL_PRIMARY_KEY_FOR_UPDATE_DELETE
    title: updateOne and deleteOne commands require filtering on the full primary key
    body: |-
      The `updateOne` and `deleteOne`commands can only filter using the fully specify the primary key for the table.

      The table ${keyspace}.${table} defines the primaryKeys: ${primaryKeyColumns}.
      The filter was missing the primary key columns: ${missingPrimaryKeyFilters}.
      
      Resend the command using a filter that fully specifies the primary key to identify a single row.

  - scope: FILTER
    code: INVALID_PRIMARY_KEY_FILTER
    title: Primary key filtering must specify columns in schema order
    body: |-
      The command requires a filter on the primary key that specifies all of the partitioning keys, and the partition sort keys in order.
      
      If a partition sort key is excluded, then all following partition sort keys must be excluded. 
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      
      The filter has the following issues: 
        - Missing Partition Keys: ${missingPartitionKeys}.
        - Out of order Partition Sort Keys: ${outOfOrderClusteringKeys}.
      
      Resend the command using a filter that includes all partitioning keys and optionally the partitioning sort keys in order. 

# ================================================================================================================
# Family: REQUEST         Scope: UPDATE
# ================================================================================================================

  - scope: UPDATE
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the update are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be updated.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The update included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  - scope: UPDATE
    code: INVALID_UPDATE_COLUMN_VALUES
    title: Column value in update clause is not valid
    body: |-
      Only values that are supported by the column data type can be included when updating.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The update included invalid values for the columns: ${invalidColumns}.
      
      Resend the command using only supported column values.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR
    title: Update operator is not supported by target columns
    body: |-
      Only update operators that are supported by the column type can be used in the update clause.
      
      Note, $push and $pullAll are only supported against map, set, list columns.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command used the update operator: ${operator}.
      The operation was not supported by the columns: ${unsupportedColumns}.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_DOC_ID
    title: Update operators cannot be used on _id field
    body: |-
      The command used the update operator: ${operator}.
      _id field cannot be updated using update operators.
      
      Resend the command without trying to update _id field.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_LEXICAL
    title: Update operator cannot be used on $lexical field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $lexical field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_VECTOR
    title: Update operator cannot be used on $vector field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $vector field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATOR_FOR_VECTORIZE
    title: Update operator cannot be used on $vectorize field
    body: |-
      The command used the update operator: ${operator}.
      Supported operators for $vectorize field are: $set, $setOnInsert, $unset.
      
      Resend the command using only supported update operators.

  - scope: UPDATE
    code: INVALID_PUSH_OPERATOR_USAGE
    title: The command has invalid usage of $push operator
    body: |-
      The command has invalid usage of $push operator, ${reason}.
      
      Update operator $push works for adding single element, combine $push with $each for adding multiple elements.
      
      E.G.
      Push single element to set/list. 
      {"$push": {"listColumn": "value"}}
      Push multiple elements to set/list. 
      {"$push": {"listColumn": {"$each": ["value1","value2"]}}}
      Push single entry to map.
      {"$push": {"mapColumn": ["key1", "value1"]}} or {"$push": {"mapColumn": {"key1":"value1"}}}
      Push multiple entries to map.
      {"$push": {"mapColumn": {"$each": [["key1","value1"],["key2", "value2"]]}}} or {"$push": {"mapColumn": {"$each": [{"key1":"value1"},{"key2":"value2"}]}}}

      Resend the command with valid usage of $push operator.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_DATA_TYPE
    title: Unsupported update data type
    body: |-
      Unsupported update data type: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATION
    title: Unsupported update operation
    body: |-
      Unsupported update operation: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATION_MODIFIER
    title: Unsupported update operation modifier
    body: |-
      Unsupported update operation modifier: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATION_PARAM
    title: Unsupported update operation parameter
    body: |-
      Unsupported update operation parameter: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATION_PATH
    title: Unsupported update operation path
    body: |-
      Unsupported update operation path: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATION_TARGET
    title: Unsupported update operation target
    body: |-
      Unsupported target JSON value for update operation: ${errorMessage}.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_FOR_PRIMARY_KEY_COLUMNS
    title: Primary key columns cannot be updated
    body: |-
      Columns in the primary key for the table cannot be updated. 
      
      This includes both the partitioning keys and the partitioning sort keys. 
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      The update included the following primary keys: ${updateOnPrimaryKeyColumns}.
      
      Resend the command without updating primary key columns.

  - scope: UPDATE
    code: MISSING_UPDATE_OPERATIONS
    title: Update operation requires at least one operation
    body: |-
      The command did not include any non empty update operations to change the columns in the table.
      
      Supported update operations are ${supportedUpdateOperations}.
      
      Resend the command using at least one update operation.

  - scope: UPDATE
    code: UNSUPPORTED_UPDATE_OPERATIONS_FOR_TABLE
    title: Update operation not supported by tables
    body: |-
      The command included update operations that are not supported by tables.
      
      API tables support the update operations: ${supportedUpdateOperations}.
      The update included the unsupported operations: ${usedUnsupportedUpdateOperations}.
      
      Resend the command using only supported update operations.

  - scope: UPDATE
    code: UNSUPPORTED_OVERLAPPING_UPDATE_OPERATIONS
    title: Columns cannot be changed by multiple update operations
    body: |-
      The command included multiple update operations that attempted to change the same column. For example, attempting to both $set and $unset a column.
    
      Multiple assignments attempted to change the columns: ${duplicateAssignmentColumns}.
      
      Resend the command using a single update operation for each column.

# Note UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION is a duplicate for Document scope, this one is used for Update scope.
  - scope: UPDATE
    code: UNSUPPORTED_VECTORIZE_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize requires a column with vectorize definition
    body: |-
      Vectorize can onl be performed on columns that have a vectorize configuration.
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize configuration: ${validVectorizeColumns}.
      The update included the following vector columns without vectorize configuration: ${invalidVectorizeColumns}.
      
      Resend the command vector columns with vectorize enabled.

  - scope: UPDATE
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in update clause are not supported
    body: |-
      Only supported column types can be included when updating columns in a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns that have unsupported data types: ${unsupportedColumns}.
      
      Resend the command using only supported column types.


  # ================================================================================================================
  # Family: REQUEST         Scope: WARNING
  # ================================================================================================================

  - scope: WARNING
    code: MISSING_INDEX
    title: Filter includes columns that are not indexed
    body: |-
      The filter includes columns that are not indexed. 
      
      The table ${keyspace}.${table} has the primary key: ${primaryKey}.
      And has indexes on the columns: ${indexedColumns}.
      The request filtered on the un-indexed columns: ${unindexedFilters}.
      
      Note: There may be a small delay in newly created indexes propagating through the system, this warning may be ignored if the column(s) were recently indexed.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: NOT_EQUALS_UNSUPPORTED_BY_INDEXING
    title: Use of $ne (not equals) on indexed columns
    body: |-
      The filter uses $ne (not equals) on columns that, while indexed, are still inefficient to filter on using not equals.  
      
      Filtering using $ne on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $ne to the columns: ${inefficientFilters}.
      
      ${SNIPPET.INEFFICIENT_FILTER}


  - scope: WARNING
    code: COMPARISON_FILTER_UNSUPPORTED_BY_INDEXING
    title: Use of $lt, $gt, $lte, $gte (comparison filter) on indexed columns
    body: |-
      The filter uses $lt, $gt, $lte, $gte (comparison filters) on columns that, while indexed, are still inefficient to filter on.  
      
      Filtering using $lt, $gt, $lte, $gte on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $lt, $gt, $lte, $gte to the indexed columns: ${inefficientFilterColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: NOT_IN_FILTER_UNSUPPORTED_BY_INDEXING
    title: Use of $nin on indexed columns
    body: |-
      The filter uses $nin on columns that, while indexed, are still inefficient to filter on.  
      
      Filtering using $nin on columns of type ${inefficientDataTypes} is inefficient, even when the columns are indexed.
      
      The table ${keyspace}.${table} uses these data types for the columns: ${inefficientColumns}.
      The request applied $nin to the indexed columns: ${inefficientFilterColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: ZERO_FILTER_OPERATIONS
    title: Zero operations provided in query filter
    body: |-
      Zero filters were provided in the filter for this query. 
      
      Providing zero filters will return all rows in the table, which may have poor performance when the table is large. For the best performance, include one or more filters using the primary key or indexes.
      
      The table ${keyspace}.${table} has the primary key: ${primaryKey}.
      And has indexes on the columns: ${indexedColumns}.
      
      ${SNIPPET.INEFFICIENT_FILTER}

  - scope: WARNING
    code: INCOMPLETE_PRIMARY_KEY_FILTER
    title: Incomplete filter on table primary key
    body: |-
      The filter only specified columns from the primary key, but did not specify the full primary key for the table.  
      
      The table ${keyspace}.${table} defines the primary keys: ${primaryKeys}.
      The filter has the following issues: 
        - Missing Partition Keys: ${missingPartitionKeys}.
        - Out of order Partition Sort Keys: ${outOfOrderClusteringKeys}.
      
      For the best performance, filter on all partition columns and optionally on clustering columns in the order they are specified. 
      
      ${SNIPPET.INEFFICIENT_FILTER}      

  - scope: WARNING
    code: DEPRECATED_COMMAND
    title: Deprecated command
    body: |-
      A deprecated command was used, it may still be used but will be removed in future releases.
      
      The deprecated command is: ${deprecatedCommand}.
      The new command to use is: ${replacementCommand}.
      
      Please check the documentation for the new command and update your code.

  - scope: WARNING
    code: QUERY_RETRIED_DUE_TO_INDEXING
    title: Query was retried due lack of primary or index usage
    body: |-
      The Data API failed to detect that the query generated by the command was inefficient due to a lack of primary key or index usage, and so it was retried after failing.
      
      To avoid needing to retry queries the Data API attempts to identify inefficient queries to the database before executing them, when doing this it can also provide detailed guidance on how to improve the command filter. If the analysis fails the query may need to be retried. 
      
      The original query used the CQL: ${originalCql}.
      The original query used the parameters: ${originalParameters}.
      
      The API appended the CQL optional `ALLOW FILTERING` to the query and retried.
      
      ${SNIPPET.INEFFICIENT_FILTER}


  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING
    title: Sorting by non partition sorting columns
    body: |-
      The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.
            
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The command sorted on the columns: ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_SKIP_OPTIONS
    title: Sorting uses skip option, performing as in memory sort
    body: |-
      Sorting uses skip option, performing as in memory sort

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_PARTITION_KEY_NOT_RESTRICTED
    title: Sorting with partition key not restricted correctly in filter clause
    body: |-
      The command wants to perform sort, however the filter clause does not have partition keys correctly restricted.
      
      When sorting by the partition sorting columns, partition keys needs to restricted by $eq in filter clause.
      
      The table ${keyspace}.${table} has the partition keys: ${partitionKeys}.
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause used the columns (in order) : ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_MISSING_PARTITION_SORTING
    title: Sorting with missing partition sorting columns
    body: |-
      The command used columns in the sort clause that are all part of the partition sorting, however the sort clause was missing some of the partition sorting columns.
      
      When sorting by the partition sorting columns, if a column is skipped then all following columns must also be skipped.
      
      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause skipped a column and then included the columns : ${outOfOrderClusteringKeys}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  - scope: WARNING
    code: IN_MEMORY_SORTING_DUE_TO_OUT_OF_ORDER_PARTITION_SORTING
    title: Sorting on out of order partition sorting columns
    body: |-
      The command used columns in the sort clause that are all part of the partition sorting, however the sort clause used a different column order to the partition sorting.

      When sorting by the partition sorting columns, the columns must be in the same order as the partition sorting.

      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The sort clause used the columns (in order) : ${sortColumns}.
      
      ${SNIPPET.INEFFICIENT_SORT}

  # ================================================================================================================
  # Family: REQUEST         Scope: PROJECTION
  # ================================================================================================================

  - scope: PROJECTION
    code: UNSUPPORTED_COLUMN_TYPES
    title: Column types in projection are not supported
    body: |-
      Only supported column types can be included when reading from a table.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command included the following columns cannot be read: ${unsupportedColumns}.
      
      Resend the command using only supported column types.

  - scope: PROJECTION
    code: UNSUPPORTED_PROJECTION_DEFINITION
    title: Unsupported projection definition
    body: |-
      Unsupported projection definition JSON value: must be Object, was ${projectionValueType}.
      
      Resend the command with valid projection definition.

  - scope: PROJECTION
    code: UNSUPPORTED_PROJECTION_PARAM
    title: Unsupported projection parameter
    body: |-
      Unsupported projection parameter: ${errorMessage}.
      
      Resend the command with valid projection definition.

  - scope: PROJECTION
    code: UNKNOWN_TABLE_COLUMNS
    title: Columns in the projection are not defined in the table schema
    body: |-
      Only columns defined in the table schema can be included in the projection.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The projection included the following unknown columns: ${unknownColumns}.
      
      ${SNIPPET.RESEND_USING_ONLY_DEFINED_COLUMNS}

  # ================================================================================================================
  # Family: REQUEST         Scope: SCHEMA
  # ================================================================================================================

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_COLUMNS
    title: Columns with the same name are defined in the table schema
    body: |-
      Column names must be unique in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The request included the following duplicate columns: ${duplicateColumns}.
      
      Resend the command using only new columns.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_FIELD
    title: Field with the same name are defined in the type definition
    body: |-
      The command attempted to add a field with a name that already exists in the type definition.
      
      The command altered the type: ${typeName}.
      The existing field name was: ${existingField}.
      
      Resend the command using only new field names.

  - scope: SCHEMA
    code: CANNOT_ANALYZE_ENTRIES_ON_MAP_COLUMNS
    title: Can not create index on map column with index function entries and specify analyze options
    body: |-
      Index function `entries` can not apply to map column when analyze options are specified.
      
      The command contains analyze options: ${analyzedOptions}.
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      
      Resend the command without options.

  - scope: SCHEMA
    code: CANNOT_DROP_PRIMARY_KEY_COLUMNS
    title: Primary key columns cannot be dropped from the table schema
    body: |-
      Primary key columns cannot be dropped from the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The table has the primary keys: ${primaryKeys}.
      The command attempted to drop the primary key columns: ${droppedColumns}. 
      
      Resend the command without dropping the primary key columns.
      

  - scope: SCHEMA
    code: CANNOT_DROP_TYPE_USED_BY_TABLE
    title: Type cannot be dropped if used by tables
    body: |-
      The command attempted to drop a type that is used by tables.
      
      The command attempted to drop the type: ${usedType}.
      The command is used by the tables: ${tableNames}.
      
      Resend the command using a type that is not used by a table.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_COLUMNS
    title: Columns cannot be dropped if they are not defined in the table schema
    body: |-
      The command attempted to drop columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to drop the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_DROP_INDEXED_COLUMNS
    title: Columns used in the indexes cannot be dropped
    body: |-
      Columns that are indexed cannot be dropped from the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has indexes on the columns: ${indexedColumns}.
      The command attempted to drop the indexed columns: ${droppedIndexedColumns}.
      
      Resend the command without dropping the indexed columns.

  - scope: SCHEMA
    code: CANNOT_RENAME_UNKNOWN_TYPE_FIELD
    title: Field cannot be renamed if it is not defined in the type
    body: |-
      The command attempted to rename a field that is not defined in the named type.
      
      The command altered the type: ${typeName}.
      The unknown field was: ${unknownField}.
      
      Resend the command using only fields defined in the type.



  - scope: SCHEMA
    code: CANNOT_VECTORIZE_UNKNOWN_COLUMNS
    title: Columns cannot be vectorized if they are not defined in the table schema
    body: |-
      The command attempted to vectorize columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to vectorize the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_DROP_VECTORIZE_FROM_UNKNOWN_COLUMNS
    title: Vectorize configuration cannot be dropped from columns if they are not defined in the table schema
    body: |-
      The command attempted to drop vectorize configuration from columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to drop vectorize configuration from the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: CANNOT_VECTORIZE_NON_VECTOR_COLUMNS
    title: Columns cannot be vectorized if they are not `vector` type
    body: |-
      Columns can only be vectorized if they use the `vector` column type.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to vectorize the non-vector columns: ${nonVectorColumns}.
      
      Resend the command using only columns that use the `vector` type.

  - scope: SCHEMA
    code: COLLECTION_NOT_EXIST
    title: Collection or table does not exist
    body: |-
      No collection or table with name '${collection}' exists.

  - scope: SCHEMA
    code: DEPRECATED_AI_MODEL
    title: Cannot use deprecated model.
    body: |-
      The command attempted to create or alter a collection or table to use a AI Model that has been marked as deprecated. Deprecated models are only supported by the API for existing use and will later be removed.

      The model is: ${model}. It is at ${modelStatus} status.
      ${message}
      
      Resend the command using supported model.

  - scope: SCHEMA
    code: EMBEDDING_SERVICE_NOT_CONFIGURED
    title: Embedding service not configured for collection
    body: |-
      Collection '${table}' does not have embedding service configured: cannot vectorize data.
      
      Collection must be recreated with embedding service configuration to allow vectorization.

  - scope: SCHEMA
    code: END_OF_LIFE_AI_MODEL
    title: Cannot use end of life model.
    body: |-
      The command attempted to use an AI Model that has been marked as end of life. End of life models cannot be used in any way. Collections or tables that use the model must be recreated as data such as embeddings is not transferrable.
      
      The model is: ${model}. It is at ${modelStatus} status.
      ${message}
      
      Resend the command using supported model.

  - scope: SCHEMA
    code: EXISTING_COLLECTION_DIFFERENT_SETTINGS
    title: Collection already exists with different settings
    body: |-
      Collection '${collectionName}' already exists but with settings different from ones passed with 'createCollection' command.

      If you need to change collection settings you will need to 'deleteCollection', then re-create with new settings.

  - scope: SCHEMA
    code: EXISTING_TABLE_NOT_DATA_API_COLLECTION
    title: Existing table not a valid Data API collection
    body: |-
      Attempt to create new collection failed: table '${tableName}' already exists and it is not a valid Data API collection.

      Recommend deleting the table and resending the command.

  - scope: SCHEMA
    code: CANNOT_DROP_VECTORIZE_FROM_NON_VECTOR_COLUMNS
    title: Vectorize configuration cannot be dropped from columns if they are not `vector` type
    body: |-
      Columns can only have the vectorize configuration dropped if they use the `vector` column type.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      And has the vector columns: ${vectorColumns}.
      The command attempted to drop vectorize config from the non-vector columns: ${nonVectorColumns}.  
      
      Resend the command using only columns that use the `vector` type.

  - scope: SCHEMA
    code: INVALID_CREATE_COLLECTION_OPTIONS
    title: Invalid options for createCollection
    body: |-
      'createCollection' command option(s) invalid: ${message}
      
      Resend 'createCollection' with valid options.

  - scope: SCHEMA
    code: INVALID_INDEXING_DEFINITION
    title: Invalid indexing definition
    body: |-
      'createCollection' indexing definition invalid: ${errorMessage}.
      
      Resend 'createCollection' with valid indexing definition.

  - scope: SCHEMA
    code: INVALID_USAGE_OF_VECTORIZE
    title: Invalid use of '$vector' and '$vectorize'
    body: |-
      '$vector' and '$vectorize' cannot be used together in same document${extraDesc}.
      
      Resend command with only '$vector' or '$vectorize'.

  - scope: SCHEMA
    code: LEXICAL_NOT_AVAILABLE_FOR_DATABASE
    title: Lexical search is not available on this database
    body: |-
      The command attempted to enable lexical search functionality but lexical search is not supported by this database.

  - scope: SCHEMA
    code: LEXICAL_NOT_ENABLED_FOR_COLLECTION
    title: Lexical search is not enabled for the collection
    body: |-
      Lexical content can only be added and filtering and sort only be used on collections for which Lexical feature is enabled.
      The collection ${keyspace}.${table} does not have Lexical feature enabled.

  - scope: SCHEMA
    code: MISSING_PARTITION_COLUMNS
    title: Partitioning keys are required for tables
    body: |-
      The table definition must have at least one partition key.
      
      ${SNIPPET.EXPLAIN_PARTITIONING}
      
      The table definition includes the columns: ${tableColumns}.
      
      Resend the command using at least one partition key. 

  - scope: SCHEMA
    code: MISSING_ALTER_TABLE_OPERATIONS
    title: Alter table command must include operations
    body: |-
      The `alterTable` command must contain at least one operation to alter the table schema, such as adding or dropping columns.
      
      The command included the empty operation: ${missingTableOperation}
      
      Resend the command including changes to the table.

  - scope: SCHEMA
    code: MISSING_ALTER_TYPE_OPERATIONS
    title: Alter type command must include operations
    body: |-
      The `alterType` command must contain at least one operation to alter the type schema, such as adding or renaming fields.
      
      Resend the command including changes to the type.

  - scope: SCHEMA
    code: MISSING_DIMENSION_IN_VECTOR_COLUMN
    title: Dimension is required for vector column if embedding service is not specified
    body: |-
      The dimension is required for vector columns if the embedding service is not specified.
      
      The command attempted to create the vector column without a dimension.
      
      Resend the command using a dimension for the vector columns.

  - scope: SCHEMA
    code: MISSING_FIELDS_FOR_TYPE_CREATION
    title: At least one field is required for type creation
    body: |-
      The type definition must have at least one field.
      
      Resend the command providing at least one field. 

  - scope: SCHEMA
    code: RERANKING_FEATURE_NOT_ENABLED
    title: Reranking feature not enabled
    body: |-
      Reranking feature is not enabled for this database.

  - scope: SCHEMA
    code: RERANKING_SERVICE_TYPE_UNAVAILABLE
    title: Reranking service type unavailable
    body: |-
      Reranking service type unavailable: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_UNEXPECTED_RESPONSE
    title: Unexpected response from reranking provider
    body: |-
      Reranking provider returned an unexpected response: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_CLIENT_ERROR
    title: Reranking provider client error
    body: |-
      Reranking provider client error: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_SERVER_ERROR
    title: Reranking provider server error
    body: |-
      Reranking provider server error: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_RATE_LIMITED
    title: Reranking provider rate-limited
    body: |-
      Reranking provider rate-limited: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_TIMEOUT
    title: Reranking provider timeout
    body: |-
      Reranking provider timed out: ${errorMessage}.

  - scope: SCHEMA
    code: RERANKING_PROVIDER_AUTHENTICATION_KEY_NOT_PROVIDED
    title: Reranking provider has no authentication key
    body: |-
      No authentication key provided for reranking provider: In order to rerank, please provide the reranking API key.

  - scope: SCHEMA
    code: TOO_MANY_COLLECTIONS
    title: Too many collections
    body: |-
      Cannot create collection '${table}': the maximum number of collections per database is ${collectionMaxCount}, database already has ${collectionCount}.

  - scope: SCHEMA
    code: UNKNOWN_DATA_TYPE
    title: Data type is unknown
    body: |-
      The column definition used a data type that is not known.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The supported data types are: ${supportedTypes}.
      The command used the unsupported data type: ${unsupportedType}.
      
      Resend the command using a known data types.

  - scope: SCHEMA
    code: UNKNOWN_KEYSPACE
    title: Keyspace does not exist in the Database
    body: |-
      The command tried to use a Keyspace that does not exist in the Database.

      The keyspace used by the command: ${keyspace}.

      Resend the command using a Keyspace that exists.

  - scope: SCHEMA
    code: UNKNOWN_PARTITION_SORT_COLUMNS
    title: Partition sort columns are not defined in the table schema
    body: |-
      The columns used for partition sorting are not present in the table schema.
      
      The table definition includes the columns: ${tableColumns}.
      The partition sort includes the unknown columns: ${unknownColumns}.
      
      Resend the command using only columns included in the table definition.

  - scope: SCHEMA
    code: UNKNOWN_PARTITION_COLUMNS
    title: Partition columns are not defined in the table schema
    body: |-
      The column used to partition by are not present in the table schema.
      
      The table definition includes the columns: ${tableColumns}.
      The partition includes the unknown columns: ${unknownColumns}.
      
      Resend the command using only columns included in the table definition.

  - scope: SCHEMA
    code: UNKNOWN_USER_DEFINED_TYPE
    title: User defined type is unknown
    body: |-
      The column uses a user defined type that is not known.
      
      ${driverMessage}
      
      Resend the command using a known user defined type.

  - scope: SCHEMA
    code: UNKNOWN_PRIMITIVE_DATA_TYPE
    title: Primitive data type is unknown
    body: |-
      The column definition used the short hand for the data type, which only supports primitive data types.
            
      The supported primitive data types are: ${supportedTypes}.
      The command used the unsupported data type: ${unsupportedType}.
      
      Resend the command using a known primitive data type.

  - scope: SCHEMA
    code: UNSUPPORTED_DATA_TYPE_TABLE_CREATION
    title: Table creation with unsupported data types
    body: |-
      The column definition used unsupported data types for the table creation.
      
      The supported data types for table creation are: ${supportedTypes}.
      The command used the unsupported data types for table creation : ${unsupportedTypes}.
      
      Resend the command using supported data types for table creation.

  - scope: SCHEMA
    code: UNSUPPORTED_MAP_DEFINITION
    title: Map definition contains unsupported data types
    body: |-
      The command attempted to create a map column that used unsupported types for either the key or value.
      
      Maps can use most primitive types for the key and value, and userDefined types for the value.
      
      The supported key types are: ${supportedKeyTypes}.
      The supported value types are: ${supportedValueTypes}.
      
      The command used the key type: ${unsupportedKeyType}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported key and value type.

  - scope: SCHEMA
    code: UNSUPPORTED_LIST_DEFINITION
    title: List definition contains unsupported data types
    body: |-
      The command attempted to create a list column that used an unsupported type for the value.
      
      Lists can use primitive type for the value, except for counter and timeuuid.
      Lists can use userDefined type for the value.
      
      The primitive data types are: ${supportedTypes}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported value type.

  - scope: SCHEMA
    code: UNSUPPORTED_SCHEMA_NAME
    title: The used schema name is not supported
    body: |-
      The command attempted to create a ${schemaType} with a name that is not supported.
      
      The supported ${schemaType} names must not be empty, more than ${maxNameLength} characters long, or contain non-alphanumeric-underscore characters.
      The command used the unsupported ${schemaType} name: '${unsupportedSchemaName}'.
      
      Resend the command using a supported ${schemaType} name.


  - scope: SCHEMA
    code: UNSUPPORTED_SET_DEFINITION
    title: Set definition contains unsupported data types
    body: |-
      The command attempted to create a set column that used an unsupported type for the value.
      
      Sets can use primitive type for the value, except for counter and timeuuid.
      Sets can use userDefined type for the value.
      
      The primitive data types are: ${supportedTypes}.
      The command used the value type: ${unsupportedValueType}.
      
      Resend the command using a supported value type.

  - scope: SCHEMA
    code: UNSUPPORTED_TYPE_FIELDS
    title: Type definition contains unsupported fields.
    body: |-
      The command attempted to create a user defined type with field definitions that use unsupported types.
      
      The supported field data types are: ${supportedTypes}.
      The command used the unsupported types: ${unsupportedFields}.
      
      Resend the command using only supported field data types.

  - scope: SCHEMA
    code: UNSUPPORTED_VECTOR_DIMENSION
    title: Vector definition contains unsupported dimension
    body: |-
      The command attempted to create a vector column that used an unsupported configuration.
      
      The dimension of the vector must be an positive integer value.
      
      The command used the dimension: ${unsupportedValue}.
      
      Resend the command using a supported vector dimension.

  - scope: SCHEMA
    code: UNKNOWN_INDEX_COLUMN
    title: Index column is not defined in the table schema
    body: |-
      The command attempted to create an index on a column that is not in the table schema.
      
      Indexes can only be created on existing columns.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns defined in the table schema.

  - scope: SCHEMA
    code: UNKNOWN_INDEX_TYPE
    title: Index type is unknown
    body: |-
      The command attempted to create an index using an unknown type.
      
      The known index types are: ${knownTypes}.
      The command used the unknown index type: ${unknownType}.
      
      Resend the command using a known index type.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEXING_FOR_DATA_TYPES
    title: Indexing not supported by data types
    body: |-
      The command attempted to create an index on a column that uses a data type not supported for indexing.
      
      Regular indexes can only be created on primitive data types such as `text` and `int`, collection data types such as 'map', 'set' and 'list', vector columns can be indexed using the createVectorIndex command.
      
      ${SNIPPET.CURRENTLY_UNSUPPORTED}
      
      The supported primitive data types are: ${supportedTypes}.
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of the supported data types.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEXING_FOR_FROZEN_COLUMN
    title: Index creation on a frozen column is not supported
    body: |-
      The command attempted to create an index on a column that is frozen.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The table has the frozen column: ${targetColumn}.
      
      Resend the command using the non-frozen column.

  - scope: SCHEMA
    code: UNSUPPORTED_INDEX_TYPE
    title: Index type is not supported
    body: |-
      The command attempted to create an index using an unsupported type.
      
      The `indexType` field in the various `createIndex` commands is optional can be safely omitted. It is included in the output of `listIndexes` command to make it clear what type the indexes are, to make it clear which type of `createIndex` command can be used to re-create the index.
      
      The supported index types are: ${supportedTypes}.
      The command used the unsupported index type: ${unsupportedType}.
      
      Resend the command using a supported index type.    

  - scope: SCHEMA
    code: UNSUPPORTED_JSON_TYPE_FOR_TEXT_INDEX
    title: JSON value type is not supported for creating text index
    body: |-
      The command attempted to create a text index using an unsupported JSON value type.
      
      The supported JSON value types are: String, Object.
      The command used the unsupported JSON value type: ${unsupportedType}.
      
      Resend the command using a supported JSON value type.

  - scope: SCHEMA
    code: UNSUPPORTED_TEXT_ANALYSIS_FOR_DATA_TYPES
    title: Analysed text index not supported by data types
    body: |-
      The command attempted to create an index that specified text analysis on a column that uses a data type not supported for text analysis.
      
      Text analysis options `ascii`, `caseSensitive`, and `normalize` can be used on:
      1. primitive columns of type `text` or `ascii`
      2. list, set columns with value type `text` or `ascii`
      3. map columns with key type `text` or `ascii` when indexing on keys
      4. map columns with value type `text` or `ascii` when indexing on values
  
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns that support text analysis.

  - scope: SCHEMA
    code: UNSUPPORTED_TEXT_INDEX_FOR_DATA_TYPES
    title: Text index not supported by data types
    body: |-
      The command attempted to create a text index on a column that is not a `text` or `ascii` type.
      
      Text indexes can only be created on columns of type `text` or `ascii`.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to text index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of `text` type.

  - scope: SCHEMA
    code: UNSUPPORTED_VECTOR_INDEX_FOR_DATA_TYPES
    title: Vector index not supported by data types
    body: |-
      The command attempted to create a vector index on a column that is not a `vector` type.
      
      Vector indexes can only be created on columns of type `vector`, regular indexes can only be created on primitive data types such as `text` and `int` using the createIndex command.
      
      Note: Indexing for `map`, `list`, and `set` types will be added at a later date. 
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to vector index the unsupported columns: ${unsupportedColumns}.
      
      Resend the command using columns of `vector` type.

  - scope: SCHEMA
    code: UNKNOWN_VECTOR_SOURCE_MODEL
    title: Vector source model is unknown
    body: |-
      The command attempted to create an vector index using a vector source model that is not known by the API.
      
      Including the optional name of the model that created the vectors when creating a vector index can provide significant performance improvements. 
      
      The known source models are: ${knownSourceModels}.
      The command attempted to use the source model: ${unknownSourceModel}.
      
      Resend the command using a known source model.

  - scope: SCHEMA
    code: UNKNOWN_VECTOR_METRIC
    title: Vector metric is unknown
    body: |-
      The command attempted to create an vector index using a metric that is not known by the API.
            
      The metric, also known as the similarity function, used to create the vector index is used to compare vectors to find the similar vectors.
      
      The known metrics are: ${knownMetrics}.
      The command attempted to use the metric: ${unknownMetric}.
      
      Resend the command using a known metric.

  - scope: SCHEMA
    code: VECTOR_SEARCH_NOT_SUPPORTED
    title: Vector search not enabled for collection
    body: |-
      Vector search is not enabled for collection: ${keyspace}.${table}.


  - scope: SCHEMA
    code: VECTOR_SEARCH_UNKNOWN_FUNCTION_NAME
    title: Unknown vector search function name
    body: |-
      Unknown vector search function name: '${function}'.

  - scope: SCHEMA
    code: VECTOR_SEARCH_UNRECOGNIZED_SOURCE_MODEL_NAME
    title: Unrecognized vector search source model name
    body: |-
      Unrecognized vector search source model name: ${errorMessage}.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_INDEX
    title: Dropped index is not defined in the keyspace schema
    body: |-
      The command attempted to drop an index that is not in the keyspace schema.
      
      The command attempted to drop the unknown index: ${unknownIndex}.
      
      Resend the command using an index that exists in the keyspace.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_TABLE
    title: Dropped table is not defined in the keyspace schema
    body: |-
      The command attempted to drop a table that is not in the keyspace schema.
      
      The command attempted to drop the unknown table: ${unknownTable}.
      
      Resend the command using a table that exists in the keyspace.

  - scope: SCHEMA
    code: CANNOT_DROP_UNKNOWN_TYPE
    title: Dropped type is not defined in the keyspace schema
    body: |-
      The command attempted to drop a type that is not in the keyspace schema.
      
      The command attempted to drop the unknown type: ${unknownType}.
      
      Resend the command using a type that exists in the keyspace.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_TABLE
    title: Table with the same name exists in the keyspace schema
    body: |-
      The command attempted to add a table that already exists in the keyspace schema.
      
      The command attempted to add the existing table: ${existingTable}.
      
      Resend the command using a table name that does not exist in the keyspace.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_TYPE
    title: Type with the same name exists in the keyspace schema
    body: |-
      The command attempted to add a type that already exists in the keyspace schema.
      
      The command attempted to add the existing type: ${existingType}.
      
      Resend the command using a type name that does not exist in the keyspace.


  - scope: SCHEMA
    code: CANNOT_ADD_UNSUPPORTED_DATA_TYPE_COLUMNS
    title: Alter table trying to add columns with unsupported data type
    body: |-
      The command attempted to add columns with unsupported data types to the table schema.
      
      The supported data types for adding columns are: ${supportedTypes}.
      The command attempted to add columns with unsupported data types: ${unsupportedTypes}.
      
      Resend the command using supported data types to alter table.

  - scope: SCHEMA
    code: CANNOT_ADD_EXISTING_INDEX
    title: Index with the same name exists in the keyspace schema
    body: |-
      The command attempted to add an index that already exists in the keyspace schema.
      
      The command attempted to add the existing index: ${existingIndex}.
      
      Resend the command using an index name that does not exist in the keyspace.

    # prev errors - all need to be reviewed

  - scope: SCHEMA
    code: INVALID_INDEX_DEFINITION
    title: Provided index configuration is not valid.
    body: |-
      Provided index configuration is not valid: ${reason}.

  - scope: SCHEMA
    code: INVALID_KEYSPACE
    title: Keyspace used is not valid.
    body: |-
      Keyspace used is not valid: ${keyspace} 

  - scope: SCHEMA
    code: COLUMN_TYPE_INCORRECT
    title: Column data type not provided or format invalid in the definition
    body: |-
      Column data type not provided or format invalid in the definition.
      Column definition can be defined in shorthand format as: 
        "column_name": "text"
      
      or in nested object structure format as:
        "column_name": {
          "type": "text"
        }

  - scope: SCHEMA
    code: PRIMARY_KEY_DEFINITION_INCORRECT
    title: Primary key definition provided is incorrect.
    body: |-
      Primary key definition provided is incorrect.
      1. A single primary key column can be defined using the shorthand format as:
        "primaryKey": "id"
      2. A composite primary key can be defined using the advanced nested object structure format as:
        "primaryKey": {
          "partitionBy": [
            "id"
          ],
          "partitionSort": {
            "name" : 1, "age" : -1
          }
        }
        Following are checked as part of composite primary keys:
          a. partitionBy is mandatory.
          b. partitionSort is optional.
          c. partitionSort should not have the columns defined in partitionBy.
          d. partitionSort values should be either `1` for ascending or `-1` for descending.

  - scope: SCHEMA
    code: INVALID_FORMAT_FOR_INDEX_CREATION_COLUMN
    title: Unable to create index, format for index creation column is invalid.
    body: |-
      Command has an invalid format for index creation column.
      
      The column string can have different formats:
      - Primitive column: {"column": "primitiveColumn"}
      - List column: {"column": "listColumn"}
      - Set column: {"column": "setColumn"}
      - Map column:
        - Default to index on map entries: {"column": "mapColumn"}
        - Index on map keys: {"column": {"mapColumn" : "$keys"}}
        - Index on map values: {"column": {"mapColumn" : "$values"}}
      
      Resend the command using a valid format for index creation column.

  - scope: SCHEMA
    code: INVALID_USER_DEFINED_TYPE_NAME
    title: User defined type name is not valid.
    body: |-
        User defined type name is not valid: ${udtName}.
        
        The user defined type name "udtName" must not be empty.
        
        Resend the command using a valid user defined type name.

  - scope: SCHEMA
    code: INVALID_VECTORIZE_FIELD_CONFIGURATION
    title: Unable to parse vectorize configuration for table, field schema invalid.
    body: |-
      Unable to parse vectorize configuration, schema invalid for field '${field}' (of table '${keyspace}.${table}').
      Underlying problem: ${message}

  - scope: SCHEMA
    code: INVALID_VECTORIZE_TABLE_CONFIGURATION
    title: Unable to parse vectorize configuration for table.
    body: |-
      Unable to parse vectorize configuration, schema invalid for table '${keyspace}.${table}'.
      Underlying problem: ${message}

  - scope: SCHEMA
    code: COLUMN_NOT_FOUND
    title: Column doesn't exist in the table.
    body: |-
      Column `${column}` doesn't exist in the table.

  - scope: SCHEMA
    code: TOO_MANY_INDEXES_FOR_COLLECTION
    title: Cannot create collection due to number of existing indexes
    body: |-
      The command attempted to create an collection, however the number of indexes in the database has reached the maximum allowed.
      
      Failed to create Collection: ${keyspace}.${table}.
      The number of indexes needed for each collection is: ${indexesPerCollection}.
      
      Reduce the number of indexes in the database and resend the command.

  - scope: SCHEMA
    code: EXISTING_INDEX_FOR_COLLECTION
    title: Cannot create collection due to existing index with conflicting name
    body: |-
      The command attempted to create an collection, however the the name of one of the indexes needed for the collection conflicts with an existing index in the database.
      
      Failed to create Collection: ${keyspace}.${table}.
      
      Remove existing indexes with names that start with the collection name and resend the command.


# ================================================================================================================
# Family: REQUEST         Scope: SORT
# ================================================================================================================

  - scope: SORT
    code: CANNOT_LEXICAL_SORT_NON_INDEXED_COLUMNS
    title: Lexical sort cannot be used for non-indexed columns
    body: |-
      The command attempted to lexical sort on column that is not indexed.
      
      Lexical sorting is only supported on columns that have been indexed.
      
      ${SNIPPET.LEXICAL_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} has indexes on columns: ${indexedColumns}.
      The command attempted to sort columns: ${sortColumn}.
      
      Resend the command using indexed column.

  - scope: SORT
    code: CANNOT_LEXICAL_SORT_WITH_SKIP_OPTION
    title: Skip option cannot be used with lexical sort
    body: |-
      The command attempted to lexical sort column along with skip option set.
      
      ${SNIPPET.LEXICAL_SORT_EXPLANATION}
      
      Resend the command without the skip option.

  - scope: SORT
    code: CANNOT_SORT_ON_MULTIPLE_VECTORS
    title: More than one vector sort provided
    body: |-
      The command used a sort clause with more than one vector sort, only one vector sort is allowed.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to vector sort on the columns: ${sortColumns}.
      
      Resend the command with only one vector sort.

  - scope: SORT
    code: CANNOT_SORT_ON_MULTIPLE_VECTORIZE
    title: More than one vectorize sort provided
    body: |-
      The command used a sort clause with more than one vectorize sort, only one vectorize sort is allowed. 

      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to vectorize sort on the columns: ${sortColumns}.
      
      Resend the command with only one vectorize sort.

  - scope: SORT
    code: CANNOT_SORT_ON_SPECIAL_WITH_OTHERS
    title: Special sort combined with other sort expressions
    body: |-
      The command used a sort clause with a special (lexical/vector/vectorize) sort combined with one or more other sort expressions:
      Special sorts can only be used on their own, and cannot be combined with other sort expressions.
      
      The command attempted to use lexical sort on columns: ${lexicalSorts}.
      The command attempted to use vector/vectorize sort on columns: ${vectorSorts}.
      The command attempted to use regular sort on columns: ${regularSorts}.
      
      Resend the command with only one special sort expression.

  - scope: SORT
    code: CANNOT_SORT_UNKNOWN_COLUMNS
    title: Sorted columns are not defined in the table schema
    body: |-
      The command attempted to sort using columns that are not in the table schema.
      
      The table ${keyspace}.${table} defines the columns: ${allColumns}.
      The command attempted to sort the unknown columns: ${unknownColumns}.  
      
      Resend the command using only columns that are defined in the table schema.

  - scope: SORT
    code: OVERLOADED_SORT_ROW_LIMIT
    title: Sort aborted due to in-memory sort restriction
    body: |-
      The command used in-memory sorting which has a limit of ${maxLimit} ${unit}s. 
      
      Consult any warnings included in the response for how to improve the sort performance.
      
      Resend the command using a more specific filter to reduce the number of ${unit}s sorted.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_NON_VECTOR_COLUMNS
    title: Vector sort columns are not `vector` type
    body: |-
      The command attempted to vector sort on a column that is not of `vector` type.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines vector columns: ${vectorColumns}.
      The command attempted to sort the non-vector columns: ${sortColumns}.
      
      Resend the command using only `vector` columns.

  - scope: SORT
    code: CANNOT_VECTORIZE_SORT_NON_VECTOR_COLUMN
    title: Vectorize sort columns are not `vector` type
    body: |-
      The command attempted to vectorize sort on a column that is not of `vector` type.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines vector columns: ${vectorColumns}.
      The command attempted to sort the non-vector columns: ${sortColumns}.
      
      Resend the command using only `vector` columns with vectorize enabled.

  - scope: SORT
    code: CANNOT_VECTORIZE_SORT_WHEN_MISSING_VECTORIZE_DEFINITION
    title: Vectorize sort not supported on column with missing vectorize configuration
    body: |-
      Vectorize sort can only be used with columns that have a vectorize configuration. 
      
      ${SNIPPET.ADD_VECTORIZE_CONFIG}
      
      The table ${keyspace}.${table} defines the vector columns with vectorize definition: ${validVectorizeColumns}.
      The command included the following vector columns without vectorize definition: ${invalidVectorizeColumns}.
      
      Resend the command using only `vector` columns with a vectorize definition.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_WITH_LIMIT_EXCEEDS_MAX
    title: Limit exceeds the maximum allowed for vector sort
    body: |-
        The command attempted to vector sort columns with a limit that exceeds the maximum allowed.
        
        Vector sorting is limited to a maximum of ${maxLimit} rows.
        The command attempted to sort the vector column: ${sortColumn} with a limit of ${limit}.
        
        Resend the command using a limit of ${maxLimit} or less.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_WITH_SKIP_OPTION
    title: Skip option cannot be used with  vector sort
    body: |-
      The command attempted to vector sort columns along with skip option set. 
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      Resend the command without the skip option.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_NON_INDEXED_VECTOR_COLUMNS
    title: Vector sort cannot be used for non indexed vector columns
    body: |-
      The command attempted to vector sort vector columns that are not indexed.
      
      Vector sorting is only supported on vector columns that have been indexed.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      And has indexes on the vector columns: ${indexedColumns}.
      The command attempted to sort vector columns: ${sortColumns}.  
      
      Resend the command using only indexed vector columns.

  - scope: SORT
    code: CANNOT_SORT_VECTOR_AND_NON_VECTOR_COLUMNS
    title: Vector sort cannot be used with non vector sorting
    body: |-
      The command attempted to vector sort vector columns and other non vector columns.
      
      Vector sorts must use a single vector column, and cannot include any other sort columns.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      The command attempted to sort the vector columns: ${sortVectorColumns}.
      The command attempted to sort the non-vector columns: ${sortNonVectorColumns}.
      
      Resend the command using either vector or non-vector sorting.

  - scope: SORT
    code: CANNOT_VECTOR_SORT_ON_MISMATCHED_VECTOR_DIMENSIONS
    title: Vector sort cannot be used with mismatched vector dimensions
    body: |-
      The command attempted to vector sort vector columns with a mismatched vector dimension.
      Target vector column is `${targetVectorColumn}`, which has a dimension of `${actualDimension}`.
      The command provided a vector with a dimension of `${providedDimension}`.

      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      The table ${keyspace}.${table} defines the vector columns: ${vectorColumns}.
      
      Resend the command providing vector that have the same dimension as target vector column.

  - scope: SORT
    code: INVALID_REGULAR_SORT_EXPRESSION
    title: Sort expression is not valid for regular sort
    body: |-
      The command attempted to use unsupported JSON expression `${jsonExpr}` (type ${jsonType}) for sort clause.
      
      ${SNIPPET.REGULAR_SORT_EXPLANATION}
      
      Resend the command with only valid sort expressions.

  - scope: SORT
    code: INVALID_VECTOR_SORT_EXPRESSION
    title: Sort expression is not valid for vector/vectorize sort
    body: |-
      The command attempted to use unsupported JSON type (${jsonType}) for vector or vectorize sort.
      
      ${SNIPPET.VECTOR_SORT_EXPLANATION}
      
      Resend the command with valid vector/vectorize sort expression.

  - scope: SORT
    code: SORT_CLAUSE_INVALID
    title: Sort clause used by command not valid
    body: |-
      Sort clause used by command not valid.
      Problem: ${problem}.
      
      Resend the command with a valid sort clause.

  - scope: SORT
    code: SORT_CLAUSE_PATH_INVALID
    title: Path used in sort clause not valid
    body: |-
      Path '${path}' used in sort clause not valid: ${problem}.
      
      Resend the command with valid sort clause.

  - scope: SORT
    code: SORT_CLAUSE_PATH_UNINDEXED
    title: Collection field used in sort clause not indexed
    body: |-
      Collection field '${path}' is not indexed: cannot sort using it. 
      
      Resend the command with sort on an indexed field.

  - scope: SORT
    code: SORT_CLAUSE_VALUE_INVALID
    title: Value used for sort expression not valid
    body: |-
      Value used for sort expression on path '${path}' not valid: ${problem}.
      
      Resend the command with valid sort expression value.

  - scope: SORT
    code: UNSUPPORTED_SORT_FOR_TABLE_DELETE_COMMAND
    title: Sorting not supported by delete command on tables
    body: |-
      The command attempted to sort a delete command running against a table. 

      Deleting rows in a table does not support sorting, rows can only be deleted by specifying the partition key(s) and optionally the clustering key(s) for the row(s) to be deleted.
      
      Resend the command without the sort clause.

  - scope: SORT
    code: UNSUPPORTED_SORT_FOR_TABLE_UPDATE_COMMAND
    title: Sorting not supported by update command on tables
    body: |-
      The command attempted to sort a update command running against a table. 

      Updating row in a table does not support sorting, a row can only be updated by specifying full primary key(s).
      
      Resend the command without the sort clause.

  - scope: SORT
    code: UNSUPPORTED_PAGINATION_WITH_IN_MEMORY_SORTING
    title: Pagination not supported when using in-memory sorting
    body: |-
      Pagination is not supported when the data is sorted in-memory.

      The table ${keyspace}.${table} has the partition sorting columns: ${partitionSorting}.
      The command sorted on the columns: ${sortColumns}.
      
      Resend the command without pagination.    

  - scope: SORT
    code: UNSUPPORTED_VECTOR_SORT_FOR_COLLECTION
    title: Vector sorting not supported by the collection
    body: |-
      The command attempted to vector sort against a collection that does not have vectors enabled. 

      Vector sorting is enabled when creating a collection via the `vector` configuration option. It must be defined at creation time as all vectors have the same dimension.
      
      The collection ${keyspace}.${table} does not have vectors enabled.
      
      Resend the command using a collection with vectors enabled, or create a new collection.


  - scope: SORT
    code: UNSUPPORTED_VECTORIZE_SORT_FOR_COLLECTION
    title: Vectorize sorting not supported by the collection
    body: |-
      The command attempted to use vectorize sort (keyword '$vectorize' or '$hybrid') against a collection that does not have vectorize enabled.

      Vectorize allows the collection to calculate the sort vector for a text value server side.
      Vectorize is enabled when creating a collection via the `vector` configuration option, and it must be defined at creation time as all vectors have the same dimension and model.
      
      The collection ${keyspace}.${table} does not have vectorize enabled.
      
      Resend the command using a collection with vectorize enabled, or create a new vectorize-enabled collection.

# ================================================================================================================
# ================================================================================================================
#                                           Server Errors
# ================================================================================================================
# ================================================================================================================

server-errors:
  # UNSCOPED server errors
  - scope:
    code: INTERNAL_SERVER_ERROR
    title: Internal server error
    body: |-
      An unexpected internal server error occurred while processing the request. 
      
      Error Message: ${errorMessage}
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope:
    code: UNEXPECTED_SERVER_ERROR
    title: Unexpected server error
    body: |-
      An unexpected server error occurred while processing the request. 
      
      Error Class: ${errorClass}
      Error Message: ${errorMessage}
      
      ${SNIPPET.RETRY_UNKNOWN}

  # DATABASE scope server errors

  - scope: DATABASE
    code: CORRUPTED_COLLECTION_SCHEMA
    title: Corrupted collection schema
    body: |-
      The Data API failed to operate on the collection because the schema definition is corrupted.
      
      The definition of the collection in the database has changed, typically this happens when an index is removed outside of the Data API. Further operations on the collection will fail until the collection is repaired or re-created.
      
      The corrupted collection is: ${keyspace}.${table}.
      The database error: ${errorMessage}.
      
      Recreate the collection using the Data API, or contact support for assistance repairing.

  - scope: DATABASE
    code: COLLECTION_NO_INDEX_ERROR
    title: Collection missing index(es)
    body: |-
      Faulty collection (missing index(es)).
      Recommend re-creating the collection.
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    code: COLLECTION_SCHEMA_VERSION_INVALID
    title: Collection schema version invalid
    body: |-
      Collection '${collectionName}' has invalid schema version (${schemaVersion}).
      Recommend re-creating the collection.
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    code: COUNT_READ_FAILED
    title: Count read failed
    body: |-
      The Data API read from the database failed.
      
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  # Internal error: does it belong here?
  - scope: DATABASE
    code: DOCUMENT_FROM_DB_UNPARSEABLE
    title: Unable to parse JSON content
    body: |-
      Unable to parse JSON content retrieved from the database; not valid JSON.
      Underlying problem: ${errorMessage}

      Report the problem to database administrators.

  - scope: DATABASE
    code: FAILED_CONCURRENT_OPERATIONS
    title: Failed to complete concurrent operations on the database
    body: |-
      The Data API command was unable to complete an operation on a document or row due to concurrent modifications from other requests.
      
      This should be a rare error, it occurs when multiple requests attempt to modify the same document or row at the same time. The Data API has retried the operation multiple times, but was unable to complete it before another request modified the same document or row. This may indicate a "hot row" in your database, or low resources slowing down the database.
      
      NOTE: If the request updated multiple documents or rows, some of the updates may have completed successfully. Check the response for partial success information.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_TO_CONNECT_TO_DATABASE
    title: Data API Failed to connect to the database
    body: |-
      The Data API was unable to connect to any nodes in the database to process the command.
      
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: INVALID_COLLECTION_QUERY
    title: Invalid query
    body: |-
      Invalid query against a collection.
      Underlying problem: ${errorMessage}.
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    code: UNEXPECTED_DOCUMENT_ID_TYPE
    title: Unexpected stored document id type
    body: |-
      Type of document id stored in database unexpected: ${errorMessage}.
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    code: UNEXPECTED_DRIVER_ERROR
    title: Unexpected driver error
    body: |-
      An unexpected server error occurred while using the driver with the database. 
      
      The command against the ${schemaType} ${keyspace}.${table} may be in an inconsistent state due to the error encountered. It may have either: 
      * Failed to start communicating with the database.
      * Encountered an error when being processed by the database.
      * Completed successfully, but returned an unexpected response.
      
      Consult the the detailed error message below for more information:
      
      Error Class: ${errorClass}
      Error Message: ${errorMessage}
      
      ${SNIPPET.RETRY_UNKNOWN}

  - scope: DATABASE
    # NOTE: this is here as a server error because the API should have caught missing keyspace before sending to the database
    code: UNKNOWN_KEYSPACE
    title: Unknown keyspace
    body: |-
      The command referenced a keyspace that does not exist in the database. 
      
      The Data API believed the keyspace existed, but the database returned an error that the keyspace does not exist. This may be a temporary issue.
      
      The command used the keyspace: ${keyspace}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: INVALID_DATABASE_QUERY
    title: Invalid database query
    body: |-
      The Data API command generated a database query that while syntactically correct, was rejected as invalid by the database.  
      
      The Data API should have generated a valid query, or returned an error before sending the query to the database. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      Retrying the command will likely result in the same error.

  - scope: DATABASE
    code: UNSUPPORTED_DATABASE_QUERY
    title: Unsupported database query
    body: |-
      The Data API command generated a database query that was syntactically incorrect, and was rejected by the database.  
      
      The Data API should should only generate correct database syntax. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      Retrying the command will likely result in the same error.

  - scope: DATABASE
    code: FAILED_COMPARE_AND_SET
    title: Failed database Compare and Set operation
    body: |-
      The Data API command generated a database query that used the Compare and Set feature, and the database was unable to determine if the operation was successful.    
      
      This should be a rare error, and may be due to a temporary capacity issue with the database. The API uses idempotent operations when modifying documents in collections which removes the possibility of data corruption.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_TRUNCATION
    title: Failed database Truncate operation
    body: |-
      The Data API command generated a database query to truncate the table, and the database was either unable to start or complete the operation.     
      
      Truncating a collection or table requires all worker nodes in the keyspace to be available and complete the operation in the required time. Completing the operation includes flushing memory to disk and snapshotting on disk files. 
      
      This is operation has the lowest level of availability as all nodes must be involved. And so it may fail while other read and write operations success, as they do not require all nodes to be available. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: UNAVAILABLE_DATABASE
    title: The database is unavailable
    body: |-
      The Data API submitted a query to the database, but the database refused to start processing as not enough nodes available.      
      
      Queries typically require 2 out of 3 replicas to be available before they can start, though the exact numbers can vary. And the random distribution of data allows for some queries to have enough replicas, while other do not (known as partial availability).   
      
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The number of nodes required was: ${requiredNodes}.
      The number of nodes available was: ${aliveNodes}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_READ_REQUEST
    title: Failed database request
    body: |-
      The Data API command generated a database query that was syntactically correct and the database started processing, however too many nodes failed to complete the operation.     
      
      This error indicates an issue processing the request, not that the request timed out before completing. 
            
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The number of nodes that failed was: ${failedNodes}.
      The data was returned to the coordinator node was: ${dataPresent}
      The unique set of node failures reasons was: ${failureReasons}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: FAILED_WRITE_REQUEST
    title: Failed database request
    body: |-
      The Data API command generated a database query that was syntactically correct and the database started processing, however too many nodes failed to complete the operation.     
      
      This error indicates an issue processing the request, not that the request timed out before completing. 
      
      When working with collections, the data will be consistent, even when failing to write data. When working with tables, the data may be in an Eventually Consistent state, as the operation may have completed on some replicas, but not all.
      
      This may be due to a temporary capacity issue with the database, or a wider outage. 
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The number of nodes that failed was: ${failedNodes}.
      The write type was: ${writeType}.
      The unique set of node failures reasons was: ${failureReasons}.
      The database error: ${errorMessage}.
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: TIMEOUT_READING_DATA
    title: Timeout reading data from the database
    body: |-
      The Data API generated a database query that timed out before completing the operation.
      
      The query was most likely correct, but not enough nodes confirmed the operation had completed before the timeout.
            
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The data was returned to the coordinator node was: ${dataPresent}
      
      ${SNIPPET.RETRY}

  - scope: DATABASE
    code: TIMEOUT_WRITING_DATA
    title: Timeout writing data to the database
    body: |-
      The Data API generated a database query that timed out before completing the operation.
      
      The query was most likely correct, but not enough nodes confirmed the operation had completed before the timeout.
      
      For collections, that data will be consistent. When working with tables, the data may be in an Eventually Consistent state, as the operation may have completed on some replicas but not all, which can result in inconsistent reads.
      
      This may be due to a temporary capacity issue with the database, or a wider outage.
      
      The command used the keyspace and table or collection: ${keyspace}.${table}.
      The command generated the CQL query: ${cql}.
      The command generated the CQL values: ${values}.
      The number of nodes blocked for was: ${blockForNodes}.
      The number of nodes received was: ${receivedNodes}.
      The write type was: ${writeType}.
      
      ${SNIPPET.RETRY}

  # EMBEDDING scope server errors
  - scope: EMBEDDING_PROVIDER
    code: EMBEDDING_GATEWAY_NOT_AVAILABLE
    title: Embedding Gateway not available
    body: |-
      Embedding Gateway not available.
      Underlying problem: ${errorMessage}.

  - scope: EMBEDDING_PROVIDER
    code: CLIENT_ERROR
    title: The Embedding Provider returned a HTTP client error
    body: |-
      Provider: ${provider}; HTTP Status: ${httpStatus}; Error Message: ${errorMessage}

  - scope: EMBEDDING_PROVIDER
    code: SERVER_ERROR
    title: The Embedding Provider returned a HTTP client error
    body: |-
      Provider: ${provider}; HTTP Status: ${httpStatus}; Error Message: ${errorMessage}