# @author Jeff Carpenter
name: Run Performance Tests

# runs on
# * manual trigger
on:
  workflow_dispatch:
    inputs:
      docscount:
        description: 'Number of documents to use for each test'
        required: true
        type: string
        default: '1000000'
      connections:
        description: 'Number of HTTP connections to use for each test'
        required: true
        type: string
        default: '20'
  schedule:
    # schedules the tests to run nightly at 4am GMT
    # * is a special character in YAML so you have to quote this string
    - cron:  '0 4 * * *'

# global env vars, available in all jobs and steps
env:
  MAVEN_OPTS: '-Xmx4g'

jobs:
  # runs performance tests
  performance-tests:
    name: Performance tests
    runs-on: ubuntu-latest

    strategy:

      # run all tests to completion
      fail-fast: false

      # matrix props:
      matrix:
        type: [ java, native ]

        test: [ http-jsonapi-crud-basic, http-jsonapi-keyvalue, http-jsonapi-search-filter-sort ]

        include:
          - type: java
            build-ops: '-Dquarkus.container-image.build=true'
            docker-flags: ''
            docker-image: 'jsonapi'

          - type: native
            build-ops: '-Pnative -Dquarkus.native.container-build=true -Dquarkus.container-image.build=true'
            docker-flags: '-n'
            docker-image: 'jsonapi-native'

          - test: http-jsonapi-crud-basic
            keyspace: 'jsonapi_crud_basic'

          - test: http-jsonapi-keyvalue
            keyspace: 'jsonapi_keyvalue'

          - test: http-jsonapi-search-filter-sort
            keyspace: 'jsonapi_keyvalue'
    steps:
      # force checkout of main branch so we get a SHA that will have a corresponding docker image tag in ECR
      - uses: actions/checkout@v3
        with:
          ref: main

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '17'
          cache: maven

      # login to ECR to we can pull coord image from there
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.ECR_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.ECR_SECRET_KEY }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      # Use docker-compose to start required stack
      # Pull JSON API image from ECR corresponding to latest commit on main branch
      # Pull Stargate coordinator image from ECR corresponding to version dependency in project pom
      # Retag images to remove repository name since start script does not expect it
      # Print version of images used for verification
      - name: Start Docker Compose
        run: |
          JSONTAG=$(git show -s --format="%H")
          docker pull ${{ secrets.ECR_REPOSITORY }}/stargateio/${{ matrix.docker-image }}:$JSONTAG
          docker image tag ${{ secrets.ECR_REPOSITORY }}/stargateio/${{ matrix.docker-image }}:$JSONTAG stargateio/${{ matrix.docker-image }}:$JSONTAG
          SGTAG="$(./mvnw -f . help:evaluate -Dexpression=stargate.int-test.coordinator.image-tag -q -DforceStdout)"
          docker pull ${{ secrets.ECR_REPOSITORY }}/stargateio/coordinator-dse-68:$SGTAG
          docker image tag ${{ secrets.ECR_REPOSITORY }}/stargateio/coordinator-dse-68:$SGTAG stargateio/coordinator-dse-68:$SGTAG
          cd docker-compose
          ./start_dse_68_dev_mode.sh ${{ matrix.docker-flags }} -j $JSONTAG -t $SGTAG

      # Install NB and required library
      # See: https://github.com/AppImage/AppImageKit/wiki/FUSE
      # Print version to affirm correct install
      - name: Download NoSQLBench
        run: |
          sudo add-apt-repository universe
          sudo apt install libfuse2
          curl -L -O https://github.com/nosqlbench/nosqlbench/releases/latest/download/nb5
          chmod +x nb5
          ./nb5 --version

      # Run test after first obtaining an auth token
      - name: Run NoSQLBench Test
        run: |
          DOCSCOUNT=${{ inputs.docscount != null && inputs.docscount || '1000000' }}          
          CONNECTIONS=${{ inputs.connections != null && inputs.connections || '20' }}          
          cd nosqlbench
          ../nb5 -v --report-csv-to logs --log-histograms logs/hdr_metrics.log ${{ matrix.test }} jsonapi_host=localhost docscount=$DOCSCOUNT connections=$CONNECTIONS

      # Simple approach measuring size of data directory
      - name: Collect Data Size Stats
        run: |
          cd docker-compose
          DATA_DIR=$(docker-compose exec -T coordinator find /tmp -name "data")
          echo 'Num documents:' ${{ inputs.docscount }} >> $GITHUB_STEP_SUMMARY
          echo 'Data size:' $(docker-compose exec -T coordinator du -sh "$DATA_DIR/${{ matrix.keyspace }}") >> $GITHUB_STEP_SUMMARY

      - name: Save Results
        uses: actions/upload-artifact@v3
        if: ${{ always() }}
        with:
          name: ${{ matrix.test }}-${{ matrix.type }}
          path: nosqlbench/logs

